import os
import json
import re
import base64
import time
import tempfile
import pathlib
import threading
from queue import Queue
from datetime import datetime, timedelta
from email.mime.text import MIMEText

import mysql.connector
from mysql.connector import Error
import pytz
from filelock import FileLock

from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
from google.auth.transport.requests import Request

# Gemini
from google import genai
from google.genai import types

# Gemini utils
from get_mail_logics.gemini_utils import (
    parse_response_contract,
    parse_response_resident_cert,
    prompt_contract,
    prompt_resident_cert,
)
from get_mail_logics.config import API_KEY

# ì£¼ì„ ì†ì‹¤ ê°ì§€ ìœ í‹¸ (Stamp/Ink ë“±)
from get_mail_logics.pdf_annotation_guard import pdf_will_lose_objects

# --- ì „ì—­ ì„¤ì • ---
SCOPES = ['https://www.googleapis.com/auth/gmail.modify']
MYSQL_CONFIG = {
    'host': '192.168.0.114',
    'port': 3306,
    'user': 'my_pc_user',
    'password': '!Qdhdbrclf56',
    'database': 'greetlounge',
    'charset': 'utf8mb4'
}
CREDENTIALS_FILE = 'credentials_3.json'
TOKEN_FILE = 'token123.json'
ATTACHMENT_SAVE_DIR = "C:\\Users\\HP\\Desktop\\greet_db\\files\\new"

# ìŠ¤ë ˆë“œ ê°„ í†µì‹ ì„ ìœ„í•œ ê³µìœ  í
download_queue = Queue()
preprocess_queue = Queue()  # ì „ì²˜ë¦¬ í ì¶”ê°€
gemini_queue = Queue()  # Gemini íŒë‹¨ í ì¶”ê°€

# Gemini ëŒ€ìƒ ì§€ì—­
TARGET_REGIONS = ['ì„œìš¸íŠ¹ë³„ì‹œ', 'ìš¸ì‚°ê´‘ì—­ì‹œ', 'ë¶€ì‚°ê´‘ì—­ì‹œ']

# ì „ì²˜ë¦¬ ì„ê³„ê°’ ì„¤ì •
PREPROCESS_THRESHOLD_MB = 3.0  # 3MB ì´ˆê³¼ ì‹œì—ë§Œ ì „ì²˜ë¦¬
PROCESSED_DIR = "C:\\Users\\HP\\Desktop\\greet_db\\files\\processed"

# --- DB ë° Gmail API ì—°ê²° ---

def get_database_connection():
    """MySQL ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë°˜í™˜ (ìŠ¤ë ˆë“œë³„ë¡œ í˜¸ì¶œ)"""
    try:
        conn = mysql.connector.connect(**MYSQL_CONFIG)
        return conn
    except Error as e:
        print(f"âŒ MySQL ì—°ê²° ì‹¤íŒ¨: {e}")
        return None

def get_service(credentials_file, token_file):
    """Gmail ì„œë¹„ìŠ¤ ì¸ì¦ (í† í° íŒŒì¼ ì ê¸ˆ ê¸°ëŠ¥ ì¶”ê°€)"""
    creds = None
    token_lock_file = f"{token_file}.lock"
    lock = FileLock(token_lock_file)

    with lock:
        if os.path.exists(token_file):
            creds = Credentials.from_authorized_user_file(token_file, SCOPES)
        
        if not creds or not creds.valid:
            if creds and creds.expired and creds.refresh_token:
                print("ğŸ”„ Gmail í† í° ê°±ì‹  ì¤‘...")
                creds.refresh(Request())
            else:
                flow = InstalledAppFlow.from_client_secrets_file(credentials_file, SCOPES)
                creds = flow.run_local_server(port=0)
            
            with open(token_file, 'w') as token:
                token.write(creds.to_json())
    
    try:
        service = build('gmail', 'v1', credentials=creds)
        print("âœ… Gmail ì„œë¹„ìŠ¤ ì¸ì¦ ì„±ê³µ")
        return service
    except Exception as e:
        print(f"âŒ Gmail ì„œë¹„ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")
        return None

# --- ë©”ì¼ ìˆ˜ì§‘ ìŠ¤ë ˆë“œ(db_mail_thread)ìš© í•¨ìˆ˜ ---

def has_attachment(payload):
    """ì²¨ë¶€íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ë§Œ ë¹ ë¥´ê²Œ í™•ì¸ (ë‹¤ìš´ë¡œë“œ ì•ˆí•¨)"""
    if 'parts' in payload:
        for part in payload['parts']:
            if part.get('filename') or part.get('body', {}).get('attachmentId'):
                return True
            # ì¬ê·€ì ìœ¼ë¡œ ë‚´ë¶€ partë„ í™•ì¸
            if 'parts' in part and has_attachment(part):
                return True
    if payload.get('body', {}).get('attachmentId'):
        return True
    return False

def save_email_to_db(conn, thread_id, title, content, from_address, received_date, has_attach):
    """emails í…Œì´ë¸”ì— ë©”ì¼ ì •ë³´ ì €ì¥"""
    # (db_mail.pyì˜ save_email_to_db í•¨ìˆ˜ì™€ ë™ì¼)
    cursor = conn.cursor()
    try:
        sql = """
            INSERT INTO emails (thread_id, received_date, from_email_address, title, content, attached_file)
            VALUES (%s, %s, %s, %s, %s, %s)
            ON DUPLICATE KEY UPDATE 
                received_date=VALUES(received_date), from_email_address=VALUES(from_email_address),
                title=VALUES(title), content=VALUES(content), attached_file=VALUES(attached_file)
        """
        cursor.execute(sql, (thread_id, received_date, from_address, title, content, 1 if has_attach else 0))
        # print(f"âœ… (DB) ë©”ì¼ ì •ë³´ ì €ì¥: {thread_id}")
        return True
    except Error as e:
        print(f"âŒ (DB) ë©”ì¼ ì •ë³´ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def insert_new_application(conn, rn, received_date, thread_id, region, delivery_date, name, special_note):
    """subsidy_applications í…Œì´ë¸”ì— ì‹ ê·œ ì‹ ì²­ ê±´ ì‚½ì…"""
    # (db_mail.pyì˜ insert_new_application í•¨ìˆ˜ì™€ ë™ì¼, region NULL ì²˜ë¦¬ í¬í•¨)
    cursor = conn.cursor()
    try:
        sql = """
            INSERT INTO subsidy_applications 
            (RN, mail_count, recent_received_date, recent_thread_id, region, delivery_date, name, special_note, status, status_updated_at)
            VALUES (%s, 1, %s, %s, %s, %s, %s, %s, 'ì‹ ê·œ', %s)
        """
        if not delivery_date: delivery_date = None
        if not region: region = None
        now_kst = datetime.now(pytz.timezone('Asia/Seoul')).strftime('%Y-%m-%d %H:%M:%S')
        cursor.execute(sql, (rn, received_date, thread_id, region, delivery_date, name, special_note, now_kst))
        # print(f"âœ… (DB) ì‹ ê·œ ì‹ ì²­ ê±´ ì €ì¥: {rn}")
        return True
    except Error as e:
        print(f"âŒ (DB) ì‹ ê·œ ì‹ ì²­ ê±´ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def update_duplicate_application(conn, rn, new_thread_id, new_received_date):
    """ì¤‘ë³µ RN ì—…ë°ì´íŠ¸"""
    # (db_mail.pyì˜ update_duplicate_application í•¨ìˆ˜ì™€ ë™ì¼)
    cursor = conn.cursor()
    try:
        update_sql = "UPDATE subsidy_applications SET mail_count = mail_count + 1, recent_received_date = %s, recent_thread_id = %s WHERE RN = %s"
        cursor.execute(update_sql, (new_received_date, new_thread_id, rn))
        insert_sql = "INSERT INTO duplicated_rn (thread_id, RN, received_date) VALUES (%s, %s, %s)"
        cursor.execute(insert_sql, (new_thread_id, rn, new_received_date))
        # print(f"âœ… (DB) ì¤‘ë³µ ì‹ ì²­ ê±´ ì—…ë°ì´íŠ¸: {rn}")
        return True
    except Error as e:
        print(f"âŒ (DB) ì¤‘ë³µ ì‹ ì²­ ê±´ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
        return False

# --- ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ---
# (db_mail.pyì˜ í•¨ìˆ˜ë“¤, ì¼ë¶€ëŠ” ê°„ì†Œí™”)
def get_existing_rn_numbers(conn):
    cursor = conn.cursor()
    cursor.execute('SELECT RN FROM subsidy_applications')
    return {row[0] for row in cursor.fetchall()}

def get_label_id(service, label_name='RNë¶™ì„'):
    results = service.users().labels().list(userId='me').execute()
    labels = results.get('labels', [])
    return next((label['id'] for label in labels if label['name'] == label_name), None)

def safe_modify_message(service, msg_id, label_id):
    try:
        service.users().messages().modify(userId='me', id=msg_id, body={'addLabelIds': [label_id]}).execute()
        return True
    except Exception as e:
        print(f"âš ï¸ ë¼ë²¨ ì¶”ê°€ ì‹¤íŒ¨: {e}")
        return False

def extract_text_from_payload(payload):
    if 'parts' in payload:
        for part in payload['parts']:
            result = extract_text_from_payload(part)
            if result: return result
    elif payload.get('mimeType') in ['text/plain', 'text/html']:
        data = payload.get('body', {}).get('data', '')
        if data:
            try:
                text = base64.urlsafe_b64decode(data).decode('utf-8')
                if payload['mimeType'] == 'text/html':
                    text = re.sub(r'<[^>]+>', '', text)
                return re.sub(r'[ \t]+', ' ', text).strip()[:1000]
            except: return "ë‚´ìš© ë””ì½”ë”© ì‹¤íŒ¨"
    return ""

def extract_info_from_subject(subject):
    rn_match = re.search(r'RN\d{8,10}', subject)
    if not rn_match: return None
    rn_num = rn_match.group()
    
    # ë‚ ì§œ íŒŒì‹± ë° ìœ íš¨ì„± ê²€ì¦
    date_match = re.search(r'\[(\d{1,2})/(\d{1,2})\]', subject)
    date_str = None
    if date_match:
        try:
            month = int(date_match.group(1))
            day = int(date_match.group(2))
            # ë‚ ì§œ ìœ íš¨ì„± ê²€ì¦ (1-12ì›”, 1-31ì¼)
            if 1 <= month <= 12 and 1 <= day <= 31:
                date_str = f'2025-{month:02d}-{day:02d}'
            else:
                print(f"âš ï¸ ì˜ëª»ëœ ë‚ ì§œ í˜•ì‹: [{month}/{day}] - Noneìœ¼ë¡œ ì²˜ë¦¬")
        except (ValueError, IndexError) as e:
            print(f"âš ï¸ ë‚ ì§œ íŒŒì‹± ì˜¤ë¥˜: {e} - Noneìœ¼ë¡œ ì²˜ë¦¬")
    
    region_match = re.search(r'RN\d{8,10}\s*/\s*([^/]+)', subject)
    region = region_match.group(1).strip() if region_match else None
    if region and any(word in region for word in ['ë¦¬ìŠ¤', 'ìºí”¼íƒˆ']): region = 'í•œêµ­í™˜ê²½ê³µë‹¨'
    applier = None
    try:
        parts = [p.strip() for p in subject.split('/')]
        model_index = next((i for i, part in enumerate(parts) if 'Model' in part), -1)
        if model_index != -1 and model_index + 1 < len(parts) and parts[model_index + 1]:
            applier = parts[model_index + 1]
    except: pass
    return {'rn_num': rn_num, 'date': date_str, 'region': region, 'applier': applier}

def extract_special_note_from_content(content):
    if not content: return ''
    patterns = [r'\d+\.\s*íŠ¹ì´ì‚¬í•­\s*:\s*([^\n\r]+)', r'íŠ¹ì´ì‚¬í•­\s*:\s*([^\n\r]+)', r'íŠ¹ì´ì‚¬í•­\s+([^\n\r]+)']
    for p in patterns:
        match = re.search(p, content)
        if match: return match.group(1).strip()
    return ''

def parsing_special(text):
    return '' if text.startswith('ê°ì‚¬') else text

# --- ìµœì´ˆ ì‹¤í–‰ ê²€ì‚¬ í•¨ìˆ˜ ---

def send_summary_email(gmail_service, missing_emails_info):
    """ëˆ„ë½ëœ ë©”ì¼ ì •ë³´ë¥¼ ìš”ì•½í•˜ì—¬ ì´ë©”ì¼ ë°œì†¡"""
    try:
        recipients = ['gyeonggoo.lee@greetlounge.com', 'hohyung.lee@greetlounge.com', 'tesla003@greetlounge.com']
        
        # ì´ë©”ì¼ ë³¸ë¬¸ ì‘ì„±
        body_lines = [
            "ë©”ì¼ ìˆ˜ì§‘ ì‹œìŠ¤í…œ ì´ˆê¸° ê²€ì‚¬ ê²°ê³¼",
            "",
            f"ì´ {len(missing_emails_info)}ê°œì˜ ëˆ„ë½ëœ ë©”ì¼ ìŠ¤ë ˆë“œë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.",
            "",
            "=" * 50,
            ""
        ]
        
        for idx, info in enumerate(missing_emails_info, 1):
            body_lines.extend([
                f"[{idx}] Thread ID: {info['thread_id']}",
                f"    ì œëª©: {info['subject']}",
                f"    ë°œì‹ ì: {info['from_address']}",
                f"    ìˆ˜ì‹ ì¼: {info['received_date']}",
                f"    ë‚´ìš© ìš”ì•½: {info['content_preview']}",
                ""
            ])
        
        body = "\n".join(body_lines)
        
        # MIME ë©”ì‹œì§€ ìƒì„±
        message = MIMEText(body, 'plain', 'utf-8')
        message['To'] = ', '.join(recipients)
        message['Subject'] = f'[ë©”ì¼ ìˆ˜ì§‘ ì‹œìŠ¤í…œ] ëˆ„ë½ëœ ë©”ì¼ {len(missing_emails_info)}ê±´ ë°œê²¬'
        
        # Base64 URL-safe ì¸ì½”ë”©
        raw_message = base64.urlsafe_b64encode(message.as_bytes()).decode('utf-8')
        
        # Gmail APIë¡œ ë°œì†¡
        gmail_service.users().messages().send(
            userId='me',
            body={'raw': raw_message}
        ).execute()
        
        print(f"âœ… ì•Œë¦¼ ì´ë©”ì¼ ë°œì†¡ ì™„ë£Œ: {len(recipients)}ëª…")
        return True
        
    except Exception as e:
        print(f"âŒ ì•Œë¦¼ ì´ë©”ì¼ ë°œì†¡ ì‹¤íŒ¨: {e}")
        return False

def send_error_notification_email(gmail_service, error_info):
    """ë©”ì¼ ì²˜ë¦¬ ì¤‘ ë°œìƒí•œ ì˜¤ë¥˜ ì •ë³´ë¥¼ í¬í•¨í•œ ì•Œë¦¼ ì´ë©”ì¼ ë°œì†¡"""
    try:
        recipients = ['gyeonggoo.lee@greetlounge.com', 'hohyung.lee@greetlounge.com', 'tesla003@greetlounge.com']
        
        # ì´ë©”ì¼ ë³¸ë¬¸ ì‘ì„±
        body_lines = [
            "ë©”ì¼ ìˆ˜ì§‘ ì‹œìŠ¤í…œ ì˜¤ë¥˜ ì•Œë¦¼",
            "",
            f"ë©”ì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            "",
            "=" * 50,
            "",
            f"ë°œìƒ ì‹œê°„: {error_info.get('timestamp', 'ì•Œ ìˆ˜ ì—†ìŒ')}",
            f"Thread ID: {error_info.get('thread_id', 'ì•Œ ìˆ˜ ì—†ìŒ')}",
            f"ì œëª©: {error_info.get('subject', 'ì•Œ ìˆ˜ ì—†ìŒ')}",
            f"ë°œì‹ ì: {error_info.get('from_address', 'ì•Œ ìˆ˜ ì—†ìŒ')}",
            "",
            "ì˜¤ë¥˜ ë‚´ìš©:",
            f"{error_info.get('error_message', 'ì•Œ ìˆ˜ ì—†ìŒ')}",
            "",
            "=" * 50,
            "",
            "ì´ ì•Œë¦¼ì€ ìµœì´ˆ ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë§Œ ë°œì†¡ë©ë‹ˆë‹¤."
        ]
        
        body = "\n".join(body_lines)
        
        # MIME ë©”ì‹œì§€ ìƒì„±
        message = MIMEText(body, 'plain', 'utf-8')
        message['To'] = ', '.join(recipients)
        message['Subject'] = f'[ë©”ì¼ ìˆ˜ì§‘ ì‹œìŠ¤í…œ] ë©”ì¼ ì²˜ë¦¬ ì˜¤ë¥˜ ë°œìƒ - {error_info.get("thread_id", "ì•Œ ìˆ˜ ì—†ìŒ")}'
        
        # Base64 URL-safe ì¸ì½”ë”©
        raw_message = base64.urlsafe_b64encode(message.as_bytes()).decode('utf-8')
        
        # Gmail APIë¡œ ë°œì†¡
        gmail_service.users().messages().send(
            userId='me',
            body={'raw': raw_message}
        ).execute()
        
        print(f"âœ… ì˜¤ë¥˜ ì•Œë¦¼ ì´ë©”ì¼ ë°œì†¡ ì™„ë£Œ: {len(recipients)}ëª…")
        return True
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ì•Œë¦¼ ì´ë©”ì¼ ë°œì†¡ ì‹¤íŒ¨: {e}")
        return False

def initial_email_check():
    """ìµœì´ˆ ì‹¤í–‰ ì‹œ ìµœê·¼ 500ê°œ ë©”ì¼ì„ í™•ì¸í•˜ê³  DBì™€ ë¹„êµí•˜ì—¬ ëˆ„ë½ëœ ë©”ì¼ ì°¾ê¸°"""
    print("\n" + "="*50)
    print("ğŸ” ìµœì´ˆ ì‹¤í–‰ ê²€ì‚¬ ì‹œì‘: ìµœê·¼ 500ê°œ ë©”ì¼ í™•ì¸ ì¤‘...")
    print("="*50)
    
    gmail_service = get_service(CREDENTIALS_FILE, TOKEN_FILE)
    if not gmail_service:
        print("âŒ Gmail ì„œë¹„ìŠ¤ ì¸ì¦ ì‹¤íŒ¨. ì´ˆê¸° ê²€ì‚¬ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        return
    
    conn = get_database_connection()
    if not conn:
        print("âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨. ì´ˆê¸° ê²€ì‚¬ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        return
    
    try:
        # DBì— ì €ì¥ëœ ëª¨ë“  thread_id ê°€ì ¸ì˜¤ê¸°
        cursor = conn.cursor()
        cursor.execute('SELECT DISTINCT thread_id FROM emails')
        db_thread_ids = {row[0] for row in cursor.fetchall()}
        print(f"ğŸ“Š DBì— ì €ì¥ëœ ìŠ¤ë ˆë“œ ìˆ˜: {len(db_thread_ids)}")
        
        # ìµœê·¼ 500ê°œ ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸°
        all_messages = []
        page_token = None
        
        while len(all_messages) < 500:
            query_params = {
                'userId': 'me',
                'maxResults': min(500 - len(all_messages), 500)
            }
            if page_token:
                query_params['pageToken'] = page_token
            
            results = gmail_service.users().messages().list(**query_params).execute()
            messages = results.get('messages', [])
            all_messages.extend(messages)
            
            page_token = results.get('nextPageToken')
            if not page_token or len(messages) == 0:
                break
        
        print(f"ğŸ“¬ Gmailì—ì„œ ê°€ì ¸ì˜¨ ë©”ì‹œì§€ ìˆ˜: {len(all_messages)}")
        
        # ê° ë©”ì‹œì§€ì˜ thread_id í™•ì¸ (ì›ë³¸ ë©”ì‹œì§€ë§Œ)
        missing_thread_ids = []
        checked_threads = set()
        
        for msg in all_messages:
            try:
                msg_detail = gmail_service.users().messages().get(
                    userId='me', id=msg['id'], format='full'
                ).execute()
                
                thread_id = msg_detail['threadId']
                msg_id = msg_detail['id']
                
                # ì›ë³¸ ë©”ì‹œì§€ë§Œ í™•ì¸ (ìŠ¤ë ˆë“œì˜ ì²« ë²ˆì§¸ ë©”ì‹œì§€)
                if msg_id != thread_id:
                    continue
                
                # ì´ë¯¸ í™•ì¸í•œ ìŠ¤ë ˆë“œëŠ” ê±´ë„ˆë›°ê¸°
                if thread_id in checked_threads:
                    continue
                checked_threads.add(thread_id)
                
                # DBì— ì—†ëŠ” ìŠ¤ë ˆë“œ ì°¾ê¸°
                if thread_id not in db_thread_ids:
                    payload = msg_detail.get('payload', {})
                    headers = payload.get('headers', [])
                    subject = next((h['value'] for h in headers if h['name'].lower() == 'subject'), '(ì œëª© ì—†ìŒ)')
                    from_header = next((h['value'] for h in headers if h['name'].lower() == 'from'), '')
                    from_address = re.search(r'<(.+?)>', from_header).group(1) if re.search(r'<(.+?)>', from_header) else from_header
                    
                    ts = int(msg_detail.get('internalDate', 0)) / 1000
                    received_dt = datetime.fromtimestamp(ts, pytz.timezone('Asia/Seoul')).strftime('%Y-%m-%d %H:%M:%S')
                    
                    content = extract_text_from_payload(payload)
                    content_preview = content[:200] + '...' if len(content) > 200 else content
                    
                    missing_thread_ids.append({
                        'thread_id': thread_id,
                        'subject': subject,
                        'from_address': from_address,
                        'received_date': received_dt,
                        'content_preview': content_preview if content_preview else '(ë‚´ìš© ì—†ìŒ)'
                    })
                    
            except HttpError as e:
                if e.resp.status == 404:
                    continue
                else:
                    print(f"âš ï¸ ë©”ì‹œì§€ ì¡°íšŒ ì‹¤íŒ¨: {msg['id']} - {e}")
            except Exception as e:
                print(f"âš ï¸ ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {msg['id']} - {e}")
                continue
        
        print(f"ğŸ” ëˆ„ë½ëœ ìŠ¤ë ˆë“œ ìˆ˜: {len(missing_thread_ids)}")
        
        # ëˆ„ë½ëœ ë©”ì¼ì´ ìˆìœ¼ë©´ ì•Œë¦¼ ì´ë©”ì¼ ë°œì†¡
        if missing_thread_ids:
            print(f"ğŸ“§ {len(missing_thread_ids)}ê°œì˜ ëˆ„ë½ëœ ë©”ì¼ì— ëŒ€í•œ ì•Œë¦¼ ì´ë©”ì¼ ë°œì†¡ ì¤‘...")
            send_summary_email(gmail_service, missing_thread_ids)
        else:
            print("âœ… ëˆ„ë½ëœ ë©”ì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        
    except Exception as e:
        print(f"âŒ ì´ˆê¸° ê²€ì‚¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
    finally:
        if conn.is_connected():
            conn.close()
    
    print("="*50 + "\n")

# --- ë‹¤ìš´ë¡œë“œ ì›Œì»¤ ìŠ¤ë ˆë“œ(download_worker_thread)ìš© í•¨ìˆ˜ ---

def download_attachment(gmail_service, msg_id, part, save_dir, new_filename=None):
    """ë‹¨ì¼ ì²¨ë¶€íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
    try:
        filename = part.get('filename', '')
        if not filename: return None
        if 'attachmentId' in part.get('body', {}):
            attachment_id = part['body']['attachmentId']
            attachment = gmail_service.users().messages().attachments().get(
                userId='me', messageId=msg_id, id=attachment_id
            ).execute()
            file_data = base64.urlsafe_b64decode(attachment['data'])
            
            # ìƒˆ íŒŒì¼ëª…ì´ ì§€ì •ëœ ê²½ìš° ì‚¬ìš©, ì•„ë‹ˆë©´ ì›ë³¸ íŒŒì¼ëª… ì‚¬ìš©
            if new_filename:
                # ì›ë³¸ íŒŒì¼ì˜ í™•ì¥ì ìœ ì§€
                _, ext = os.path.splitext(filename)
                final_filename = f"{new_filename}{ext}"
            else:
                base_name, ext = os.path.splitext(filename)
                final_filename = filename
            
            # íŒŒì¼ëª… ì¤‘ë³µ ë°©ì§€
            counter = 1
            temp_filename = final_filename
            while os.path.exists(os.path.join(save_dir, temp_filename)):
                if new_filename:
                    temp_filename = f"{new_filename}_{counter}{ext}"
                else:
                    temp_filename = f"{base_name}_{counter}{ext}"
                counter += 1
            final_filename = temp_filename
            
            file_path = os.path.join(save_dir, final_filename)
            with open(file_path, 'wb') as f: f.write(file_data)
            print(f"  â¡ï¸ íŒŒì¼ ì €ì¥: {file_path}")
            return file_path
        return None
    except Exception as e:
        print(f"  âš ï¸ ì²¨ë¶€íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

def download_and_process_attachments(gmail_service, msg_id, payload, thread_id, save_dir, subject):
    """payloadì—ì„œ ëª¨ë“  ì²¨ë¶€íŒŒì¼ì„ ì°¾ì•„ ë‹¤ìš´ë¡œë“œí•˜ê³  í•„ìš”ì‹œ ë³‘í•©"""
    # (db_mail.pyì˜ check_attached_file ë¡œì§ì„ ì¬êµ¬ì„±)
    if not os.path.exists(save_dir): os.makedirs(save_dir)
    
    # ì œëª©ì—ì„œ RN, name, region ì¶”ì¶œ
    info = extract_info_from_subject(subject)
    new_filename = None
    
    if info and info.get('rn_num'):
        # {RN}_{name}_{region} í˜•ì‹ìœ¼ë¡œ íŒŒì¼ëª… ìƒì„±
        parts = [info['rn_num']]
        if info.get('applier'):
            parts.append(info['applier'])
        if info.get('region'):
            parts.append(info['region'])
        new_filename = '_'.join(parts)
        print(f"  ğŸ“ ìƒˆ íŒŒì¼ëª…: {new_filename}")
    
    attachment_paths = []
    
    def find_attachments_recursive(part_or_payload):
        """ì¬ê·€ì ìœ¼ë¡œ ì²¨ë¶€íŒŒì¼ partë¥¼ ì°¾ì•„ì„œ ë‹¤ìš´ë¡œë“œ"""
        if 'parts' in part_or_payload:
            for sub_part in part_or_payload['parts']:
                find_attachments_recursive(sub_part)
        
        if part_or_payload.get('filename') or part_or_payload.get('body', {}).get('attachmentId'):
            file_path = download_attachment(gmail_service, msg_id, part_or_payload, save_dir, new_filename)
            if file_path:
                attachment_paths.append(file_path)

    find_attachments_recursive(payload)

    if not attachment_paths: return 'N'
    
    unique_paths = list(set(attachment_paths))
    
    # PDF ë³‘í•© ë¡œì§ì€ ìƒëµ (í•„ìš” ì‹œ db_mail.pyì—ì„œ ê°€ì ¸ì™€ ì¶”ê°€)
    # í˜„ì¬ëŠ” íŒŒì¼ ê²½ë¡œë¥¼ ì„¸ë¯¸ì½œë¡ ìœ¼ë¡œ ì—°ê²°í•˜ì—¬ ë°˜í™˜
    return ';'.join(unique_paths)

def update_email_attachment_path(conn, thread_id, file_path, file_rendered=0):
    """emails í…Œì´ë¸”ì— ìµœì¢… ì²¨ë¶€íŒŒì¼ ê²½ë¡œ ì—…ë°ì´íŠ¸ ë° file_rendered ì„¤ì •"""
    cursor = conn.cursor()
    try:
        sql = """UPDATE emails 
                 SET attached_file = 1, 
                     attached_file_path = %s,
                     file_rendered = %s
                 WHERE thread_id = %s"""
        cursor.execute(sql, (file_path, file_rendered, thread_id))
        conn.commit()
        print(f"  âœ… (DB) ì²¨ë¶€íŒŒì¼ ì •ë³´ ì €ì¥: {thread_id} (file_rendered={file_rendered})")
    except Error as e:
        print(f"  âŒ (DB) ì²¨ë¶€íŒŒì¼ ê²½ë¡œ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
        conn.rollback()

# --- ìŠ¤ë ˆë“œ ë©”ì¸ í•¨ìˆ˜ ---

def db_mail_thread(poll_interval=20):
    """20ì´ˆë§ˆë‹¤ ìƒˆ ë©”ì¼ì„ í™•ì¸í•˜ê³  DBì— ì €ì¥, ë‹¤ìš´ë¡œë“œ íì— ì¶”ê°€"""
    print("ğŸš€ ë©”ì¼ ìˆ˜ì§‘ ìŠ¤ë ˆë“œ ì‹œì‘")
    gmail_service = get_service(CREDENTIALS_FILE, TOKEN_FILE)
    if not gmail_service: return
    
    label_id = get_label_id(gmail_service)
    if not label_id:
        print("âŒ 'RNë¶™ì„' ë¼ë²¨ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìŠ¤ë ˆë“œë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    # ì˜¤ë¥˜ ì•Œë¦¼ ë°œì†¡ ì—¬ë¶€ í™•ì¸ìš© í”Œë˜ê·¸ íŒŒì¼
    ERROR_NOTIFICATION_FLAG = 'error_notification_sent.flag'
    error_notification_sent = os.path.exists(ERROR_NOTIFICATION_FLAG)

    while True:
        print(f"\n--- {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} ---")
        print("ğŸ“¬ ìƒˆ ë©”ì¼ í™•ì¸ ì¤‘...")
        
        conn = get_database_connection()
        if not conn:
            time.sleep(poll_interval)
            continue

        try:
            results = gmail_service.users().messages().list(
                userId='me', q='newer_than:2h -label:RNë¶™ì„', maxResults=25
            ).execute()
            messages = results.get('messages', [])

            if not messages:
                print("âœ… ì²˜ë¦¬í•  ìƒˆ ë©”ì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            else:
                print(f"ğŸ” {len(messages)}ê°œì˜ ìƒˆ ë©”ì¼ ìŠ¤ë ˆë“œ ë°œê²¬. ì²˜ë¦¬ ì‹œì‘...")
                existing_rns = get_existing_rn_numbers(conn)
                
                for msg in reversed(messages):
                    try:
                        msg_detail = gmail_service.users().messages().get(
                            userId='me', id=msg['id'], format='full'
                        ).execute()
                        
                        if msg_detail['id'] != msg_detail['threadId']: continue

                        payload = msg_detail.get('payload', {})
                        headers = payload.get('headers', [])
                        subject = next((h['value'] for h in headers if h['name'].lower() == 'subject'), '')
                        thread_id = msg_detail['threadId']
                        
                        # 1. ë©”ì¼ ì •ë³´ ì¶”ì¶œ ë° DB ì €ì¥
                        content = extract_text_from_payload(payload)
                        ts = int(msg_detail.get('internalDate')) / 1000
                        received_dt = datetime.fromtimestamp(ts, pytz.timezone('Asia/Seoul')).strftime('%Y-%m-%d %H:%M:%S')
                        from_header = next((h['value'] for h in headers if h['name'].lower() == 'from'), '')
                        from_address = re.search(r'<(.+?)>', from_header).group(1) if re.search(r'<(.+?)>', from_header) else from_header

                        has_attach = has_attachment(payload)
                        save_email_to_db(conn, thread_id, subject, content, from_address, received_dt, False)  # ë‹¤ìš´ë¡œë“œ ì™„ë£Œ ì „ê¹Œì§€ 0

                        # 2. RN ì •ë³´ ì¶”ì¶œ ë° subsidy_applications ì €ì¥
                        info = extract_info_from_subject(subject)
                        if info and info.get('rn_num'):
                            rn_num = info['rn_num']
                            special_note = parsing_special(extract_special_note_from_content(content))
                            
                            if rn_num in existing_rns:
                                update_duplicate_application(conn, rn_num, thread_id, received_dt)
                            else:
                                insert_new_application(conn, rn_num, received_dt, thread_id, info.get('region'), info.get('date'), info.get('applier'), special_note)
                                existing_rns.add(rn_num)
                        
                        # 3. ë¼ë²¨ ë¶€ì°©
                        safe_modify_message(gmail_service, msg['id'], label_id)

                        # 4. ì²¨ë¶€íŒŒì¼ì´ ìˆìœ¼ë©´ ë‹¤ìš´ë¡œë“œ íì— ì¶”ê°€
                        if has_attach:
                            download_queue.put({
                                'msg_id': msg['id'],
                                'thread_id': thread_id,
                            })
                            print(f"ğŸ“ ë‹¤ìš´ë¡œë“œ íì— ì¶”ê°€: {thread_id}")

                    except HttpError as e:
                        if e.resp.status == 404: 
                            print(f"âš ï¸ 404 - ì‚­ì œëœ ë©”ì¼: {msg['id']}")
                        else: 
                            print(f"âŒ HTTP ì˜¤ë¥˜: {e}")
                            # ìµœì´ˆ ì˜¤ë¥˜ ë°œìƒ ì‹œ ì•Œë¦¼ ë°œì†¡
                            if not error_notification_sent:
                                try:
                                    error_info = {
                                        'timestamp': datetime.now(pytz.timezone('Asia/Seoul')).strftime('%Y-%m-%d %H:%M:%S'),
                                        'thread_id': msg.get('id', 'ì•Œ ìˆ˜ ì—†ìŒ'),
                                        'subject': 'HTTP ì˜¤ë¥˜',
                                        'from_address': 'ì•Œ ìˆ˜ ì—†ìŒ',
                                        'error_message': str(e)
                                    }
                                    send_error_notification_email(gmail_service, error_info)
                                    error_notification_sent = True
                                    # í”Œë˜ê·¸ íŒŒì¼ ìƒì„±
                                    try:
                                        with open(ERROR_NOTIFICATION_FLAG, 'w') as f:
                                            f.write(f"Error notification sent at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                                    except Exception:
                                        pass
                                except Exception as email_err:
                                    print(f"âš ï¸ ì˜¤ë¥˜ ì•Œë¦¼ ì´ë©”ì¼ ë°œì†¡ ì‹¤íŒ¨: {email_err}")
                    except Exception as e:
                        print(f"âŒ ë©”ì¼ ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
                        # ìµœì´ˆ ì˜¤ë¥˜ ë°œìƒ ì‹œ ì•Œë¦¼ ë°œì†¡
                        if not error_notification_sent:
                            try:
                                # ì˜¤ë¥˜ ë°œìƒí•œ ë©”ì¼ ì •ë³´ ìˆ˜ì§‘ ì‹œë„
                                thread_id = 'ì•Œ ìˆ˜ ì—†ìŒ'
                                subject = 'ì•Œ ìˆ˜ ì—†ìŒ'
                                from_address = 'ì•Œ ìˆ˜ ì—†ìŒ'
                                try:
                                    if 'msg' in locals():
                                        msg_detail_temp = gmail_service.users().messages().get(
                                            userId='me', id=msg['id'], format='metadata',
                                            metadataHeaders=['Subject', 'From']
                                        ).execute()
                                        thread_id = msg_detail_temp.get('threadId', 'ì•Œ ìˆ˜ ì—†ìŒ')
                                        headers_temp = msg_detail_temp.get('payload', {}).get('headers', [])
                                        subject = next((h['value'] for h in headers_temp if h['name'].lower() == 'subject'), 'ì•Œ ìˆ˜ ì—†ìŒ')
                                        from_header_temp = next((h['value'] for h in headers_temp if h['name'].lower() == 'from'), '')
                                        from_address = re.search(r'<(.+?)>', from_header_temp).group(1) if re.search(r'<(.+?)>', from_header_temp) else from_header_temp
                                except Exception:
                                    pass
                                
                                error_info = {
                                    'timestamp': datetime.now(pytz.timezone('Asia/Seoul')).strftime('%Y-%m-%d %H:%M:%S'),
                                    'thread_id': thread_id,
                                    'subject': subject,
                                    'from_address': from_address,
                                    'error_message': str(e)
                                }
                                send_error_notification_email(gmail_service, error_info)
                                error_notification_sent = True
                                # í”Œë˜ê·¸ íŒŒì¼ ìƒì„±
                                try:
                                    with open(ERROR_NOTIFICATION_FLAG, 'w') as f:
                                        f.write(f"Error notification sent at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                                except Exception:
                                    pass
                            except Exception as email_err:
                                print(f"âš ï¸ ì˜¤ë¥˜ ì•Œë¦¼ ì´ë©”ì¼ ë°œì†¡ ì‹¤íŒ¨: {email_err}")
                
                conn.commit()
                print("ğŸ‰ ë©”ì¼ ì²˜ë¦¬ ì™„ë£Œ.")

        except Exception as e:
            print(f"âŒ ë©”ì¸ ë£¨í”„ ì˜¤ë¥˜: {e}")
            if conn.is_connected(): conn.rollback()
            # ìµœì´ˆ ì˜¤ë¥˜ ë°œìƒ ì‹œ ì•Œë¦¼ ë°œì†¡
            if not error_notification_sent:
                try:
                    error_info = {
                        'timestamp': datetime.now(pytz.timezone('Asia/Seoul')).strftime('%Y-%m-%d %H:%M:%S'),
                        'thread_id': 'ë©”ì¸ ë£¨í”„ ì˜¤ë¥˜',
                        'subject': 'ë©”ì¸ ë£¨í”„ ì˜¤ë¥˜',
                        'from_address': 'ì•Œ ìˆ˜ ì—†ìŒ',
                        'error_message': str(e)
                    }
                    send_error_notification_email(gmail_service, error_info)
                    error_notification_sent = True
                    # í”Œë˜ê·¸ íŒŒì¼ ìƒì„±
                    try:
                        with open(ERROR_NOTIFICATION_FLAG, 'w') as f:
                            f.write(f"Error notification sent at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                    except Exception:
                        pass
                except Exception as email_err:
                    print(f"âš ï¸ ì˜¤ë¥˜ ì•Œë¦¼ ì´ë©”ì¼ ë°œì†¡ ì‹¤íŒ¨: {email_err}")
        finally:
            if conn.is_connected(): conn.close()

        print(f"â° {poll_interval}ì´ˆ í›„ì— ë‹¤ì‹œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
        time.sleep(poll_interval)

def download_worker_thread():
    """ë‹¤ìš´ë¡œë“œ íë¥¼ ê°ì‹œí•˜ê³  ì²¨ë¶€íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œ (ì „ì²˜ë¦¬ëŠ” ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ)"""
    print("ğŸš€ ë‹¤ìš´ë¡œë“œ ì›Œì»¤ ìŠ¤ë ˆë“œ ì‹œì‘")
    gmail_service = get_service(CREDENTIALS_FILE, TOKEN_FILE)
    if not gmail_service: return

    while True:
        try:
            task = download_queue.get()
            msg_id = task['msg_id']
            thread_id = task['thread_id']
            
            print(f"â¬‡ï¸ ë‹¤ìš´ë¡œë“œ ì‹œì‘: {thread_id}")

            conn = get_database_connection()
            if not conn:
                # DB ì—°ê²° ì‹¤íŒ¨ ì‹œ ì‘ì—…ì„ ë‹¤ì‹œ íì— ë„£ê³  ëŒ€ê¸°
                print("  âš ï¸ DB ì—°ê²° ì‹¤íŒ¨. ì‘ì—…ì„ íì— ë‹¤ì‹œ ì¶”ê°€í•©ë‹ˆë‹¤.")
                download_queue.put(task)
                time.sleep(10)
                continue

            try:
                msg_detail = gmail_service.users().messages().get(
                    userId='me', id=msg_id, format='full'
                ).execute()
                payload = msg_detail.get('payload', {})
                headers = payload.get('headers', [])
                subject = next((h['value'] for h in headers if h['name'].lower() == 'subject'), '')
                
                # ë‹¤ìš´ë¡œë“œ ìˆ˜í–‰
                final_path = download_and_process_attachments(
                    gmail_service, msg_id, payload, thread_id, ATTACHMENT_SAVE_DIR, subject
                )
                
                if final_path != 'N':
                    # ì„¸ë¯¸ì½œë¡ ìœ¼ë¡œ êµ¬ë¶„ëœ ì—¬ëŸ¬ íŒŒì¼ í™•ì¸
                    file_paths = final_path.split(';')
                    file_paths = [p.strip() for p in file_paths if p.strip()]
                    
                    # PDF íŒŒì¼ë“¤ë§Œ í•„í„°ë§
                    pdf_files = [p for p in file_paths if p.lower().endswith('.pdf')]
                    
                    # ì „ì²´ ìš©ëŸ‰ ê³„ì‚° (PDFë§Œ)
                    total_size_mb = sum(os.path.getsize(p) / (1024 * 1024) for p in pdf_files)
                    
                    needs_preprocess = False
                    
                    # PDFê°€ 1ê°œ ì´ìƒì´ê³  ì „ì²´ ìš©ëŸ‰ì´ 3MB ì´ˆê³¼ ì‹œ ì „ì²˜ë¦¬ í•„ìš”
                    if pdf_files and total_size_mb > PREPROCESS_THRESHOLD_MB:
                        # ì „ì²˜ë¦¬ ì „ì— ìœ„í—˜ ì£¼ì„(Stamp/Ink/FreeText ë“±) ì¡´ì¬ ì—¬ë¶€ ê²€ì‚¬
                        try:
                            has_dropping_annots = any(pdf_will_lose_objects(p) for p in pdf_files)
                        except Exception as e:
                            has_dropping_annots = False
                            print(f"  âš ï¸ ì£¼ì„ ê²€ì‚¬ ì‹¤íŒ¨(ê±´ë„ˆëœ€): {e}")

                        if has_dropping_annots:
                            needs_preprocess = False
                            print(f"  ğŸ›‘ ìœ„í—˜ ì£¼ì„ í¬í•¨ â†’ ì „ì²˜ë¦¬ ìŠ¤í‚µ, ì›ë³¸ ìœ ì§€ ({len(pdf_files)}ê°œ)")
                        else:
                            needs_preprocess = True
                            print(f"  ğŸ“ PDF íŒŒì¼ {len(pdf_files)}ê°œ, ì´ í¬ê¸°: {total_size_mb:.2f} MB â†’ ì „ì²˜ë¦¬ í•„ìš”")
                            
                            # ì „ì²˜ë¦¬ íì— ì¶”ê°€ (ì—¬ëŸ¬ íŒŒì¼ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ì „ë‹¬)
                            preprocess_queue.put({
                                'thread_id': thread_id,
                                'original_paths': pdf_files  # ì—¬ëŸ¬ íŒŒì¼ì„ ë¦¬ìŠ¤íŠ¸ë¡œ
                            })
                            print(f"  ğŸ“‹ ì „ì²˜ë¦¬ íì— ì¶”ê°€: {len(pdf_files)}ê°œ íŒŒì¼ ë³‘í•© ì˜ˆì •")
                    else:
                        if pdf_files:
                            print(f"  ğŸ“ PDF íŒŒì¼ {len(pdf_files)}ê°œ, ì´ í¬ê¸°: {total_size_mb:.2f} MB â†’ ì „ì²˜ë¦¬ ë¶ˆí•„ìš”")
                        else:
                            print(f"  ğŸ“ PDF íŒŒì¼ ì—†ìŒ â†’ ì „ì²˜ë¦¬ ë¶ˆí•„ìš”")
                    
                    # DB ì—…ë°ì´íŠ¸: file_rendered = 0 (ì•„ì§ ì „ì²˜ë¦¬ ì•ˆë¨)
                    final_paths_str = ';'.join(file_paths)
                    update_email_attachment_path(conn, thread_id, final_paths_str, file_rendered=0)

                    # ğŸ” RN/region í™•ì¸ í›„ Gemini íì— ì¶”ê°€
                    try:
                        info = extract_info_from_subject(subject)
                        rn_for_gemini = info.get('rn_num') if info else None

                        # RNì„ íŒŒì¼ëª…ì—ì„œë„ ë³´ì¡° ì¶”ì¶œ
                        if not rn_for_gemini:
                            for p in pdf_files:
                                m = re.search(r'(RN\d{8,10})', os.path.basename(p))
                                if m:
                                    rn_for_gemini = m.group(1)
                                    break

                        if rn_for_gemini:
                            cur = conn.cursor()
                            cur.execute("SELECT region FROM subsidy_applications WHERE RN=%s", (rn_for_gemini,))
                            row = cur.fetchone()
                            region = row[0] if row and len(row) > 0 else None
                            if region in TARGET_REGIONS:
                                # ì›ë³¸ PDF ì¤‘ ì²« ë²ˆì§¸ ê²½ë¡œë§Œ ì‚¬ìš©í•˜ì—¬ Gemini ì²˜ë¦¬
                                if pdf_files:
                                    gemini_queue.put({
                                        'rn': rn_for_gemini,
                                        'pdf_path': pdf_files[0],
                                        'thread_id': thread_id,
                                        'region': region,
                                    })
                                    print(f"  ğŸ¤– Gemini í ì¶”ê°€: {rn_for_gemini} ({region}) â†’ {pdf_files[0]}")
                    except Exception as e:
                        print(f"  âš ï¸ Gemini í ì¶”ê°€ ì¤‘ ì˜¤ë¥˜: {e}")
                
                print(f"âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {thread_id}")

            except Exception as e:
                print(f"âŒ ë‹¤ìš´ë¡œë“œ ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {thread_id}, {e}")
            finally:
                if conn.is_connected(): conn.close()
                download_queue.task_done()

        except Exception as e:
            # í ìì²´ì˜ ë¬¸ì œ ë“± ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜
            print(f"âŒ ì›Œì»¤ ìŠ¤ë ˆë“œ ì˜¤ë¥˜: {e}")
            time.sleep(5)


def preprocess_worker_thread():
    """âœ¨ ì „ì²˜ë¦¬ íë¥¼ ê°ì‹œí•˜ê³  ëŒ€ìš©ëŸ‰ PDF ìµœì í™” ìˆ˜í–‰ (ì—¬ëŸ¬ íŒŒì¼ ë³‘í•©)"""
    print("ğŸš€ ì „ì²˜ë¦¬ ì›Œì»¤ ìŠ¤ë ˆë“œ ì‹œì‘")
    
    # ì „ì²˜ë¦¬ ë””ë ‰í† ë¦¬ ìƒì„±
    if not os.path.exists(PROCESSED_DIR):
        os.makedirs(PROCESSED_DIR)

    while True:
        try:
            task = preprocess_queue.get()
            thread_id = task['thread_id']
            original_paths = task.get('original_paths', [])  # ë¦¬ìŠ¤íŠ¸ë¡œ ë°›ìŒ
            
            # ë‹¨ì¼ íŒŒì¼ì¸ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ (í•˜ìœ„ í˜¸í™˜ì„±)
            if not isinstance(original_paths, list):
                original_paths = [original_paths]
            
            if not original_paths:
                preprocess_queue.task_done()
                continue
            
            # ì „ì²´ íŒŒì¼ í¬ê¸° ê³„ì‚°
            total_size_mb = sum(os.path.getsize(p) / (1024 * 1024) for p in original_paths)
            print(f"ğŸ”§ ì „ì²˜ë¦¬ ì‹œì‘: {len(original_paths)}ê°œ íŒŒì¼, ì´ {total_size_mb:.2f} MB")
            
            try:
                # ì—¬ëŸ¬ PDFë¥¼ í•˜ë‚˜ë¡œ ë³‘í•© + ì „ì²˜ë¦¬
                merged_processed_path = merge_and_preprocess_pdfs(original_paths, PROCESSED_DIR, thread_id)
                
                if merged_processed_path:
                    # âœ¨ DB ì—…ë°ì´íŠ¸: ë³‘í•©ëœ íŒŒì¼ í•˜ë‚˜ì˜ ê²½ë¡œë¡œ êµì²´
                    conn = get_database_connection()
                    if conn:
                        try:
                            cursor = conn.cursor()
                            
                            # ì „ì²˜ë¦¬ëœ íŒŒì¼ í¬ê¸°
                            processed_size_mb = os.path.getsize(merged_processed_path) / (1024 * 1024)
                            
                            # DB ì—…ë°ì´íŠ¸: ë³‘í•©ëœ íŒŒì¼ ê²½ë¡œë§Œ ì €ì¥
                            sql = """UPDATE emails 
                                     SET attached_file_path = %s,
                                         file_rendered = 1
                                     WHERE thread_id = %s"""
                            cursor.execute(sql, (merged_processed_path, thread_id))
                            conn.commit()
                            
                            print(f"  âœ… ë³‘í•© ë° ì „ì²˜ë¦¬ ì™„ë£Œ:")
                            print(f"     ì›ë³¸: {len(original_paths)}ê°œ íŒŒì¼, {total_size_mb:.2f} MB")
                            print(f"     ì „ì²˜ë¦¬: 1ê°œ íŒŒì¼, {processed_size_mb:.2f} MB")
                            print(f"     ì €ì¥ ê²½ë¡œ: {merged_processed_path}")
                            
                        except Error as e:
                            print(f"  âš ï¸ DB ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
                            conn.rollback()
                        finally:
                            if conn.is_connected():
                                conn.close()
                else:
                    print(f"  âš ï¸ ì „ì²˜ë¦¬ ì‹¤íŒ¨: (ì›ë³¸ íŒŒì¼ ì‚¬ìš©)")
                
            except Exception as e:
                print(f"  âŒ ì „ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
                import traceback
                traceback.print_exc()
            finally:
                preprocess_queue.task_done()
                
        except Exception as e:
            print(f"âŒ ì „ì²˜ë¦¬ ì›Œì»¤ ì˜¤ë¥˜: {e}")
            time.sleep(5)


def save_contract_to_mysql(rn: str, data: dict) -> bool:
    """test_ai_êµ¬ë§¤ê³„ì•½ì„œ í…Œì´ë¸” UPSERT"""
    try:
        conn = get_database_connection()
        if not conn:
            return False
        cursor = conn.cursor()

        ai_ê³„ì•½ì¼ì = data.get('order_date') if data else None
        ai_ì´ë¦„ = data.get('customer_name') if data else None
        ì „í™”ë²ˆí˜¸ = data.get('phone_number') if data else None
        ì´ë©”ì¼ = data.get('email') if data else None
        ì°¨ì¢… = data.get('vehicle_config') if data else None

        sql = (
            """
            INSERT INTO test_ai_êµ¬ë§¤ê³„ì•½ì„œ (RN, modified_date, ai_ê³„ì•½ì¼ì, ai_ì´ë¦„, ì „í™”ë²ˆí˜¸, ì´ë©”ì¼, ì°¨ì¢…)
            VALUES (%s, NOW(), %s, %s, %s, %s, %s)
            ON DUPLICATE KEY UPDATE
                modified_date = VALUES(modified_date),
                ai_ê³„ì•½ì¼ì = VALUES(ai_ê³„ì•½ì¼ì),
                ai_ì´ë¦„ = VALUES(ai_ì´ë¦„),
                ì „í™”ë²ˆí˜¸ = VALUES(ì „í™”ë²ˆí˜¸),
                ì´ë©”ì¼ = VALUES(ì´ë©”ì¼),
                ì°¨ì¢… = VALUES(ì°¨ì¢…)
            """
        )
        cursor.execute(sql, (rn, ai_ê³„ì•½ì¼ì, ai_ì´ë¦„, ì „í™”ë²ˆí˜¸, ì´ë©”ì¼, ì°¨ì¢…))
        conn.commit()
        return True
    except Exception as e:
        print(f"âŒ MySQL ì €ì¥ ì‹¤íŒ¨(êµ¬ë§¤ê³„ì•½ì„œ) {rn}: {e}")
        try:
            if conn and conn.is_connected():
                conn.rollback()
        except Exception:
            pass
        return False
    finally:
        try:
            if conn and conn.is_connected():
                conn.close()
        except Exception:
            pass


def save_resident_cert_to_mysql(rn: str, data: dict) -> bool:
    """test_ai_ì´ˆë³¸ í…Œì´ë¸” UPSERT"""
    try:
        conn = get_database_connection()
        if not conn:
            return False
        cursor = conn.cursor()

        address_1 = (data or {}).get('address_1')
        address_2 = (data or {}).get('address_2')
        at_date = (data or {}).get('at_date')
        birth_date = (data or {}).get('birth_date')
        name = (data or {}).get('name')
        issue_date = (data or {}).get('issue_date')
        page_number = (data or {}).get('page_number')
        page_number_json = json.dumps(page_number) if page_number else None

        sql = (
            """
            INSERT INTO test_ai_ì´ˆë³¸ (RN, modified_date, address_1, address_2, at_date, birth_date, name, issue_date, page_number)
            VALUES (%s, NOW(), %s, %s, %s, %s, %s, %s, %s)
            ON DUPLICATE KEY UPDATE
                modified_date = VALUES(modified_date),
                address_1 = VALUES(address_1),
                address_2 = VALUES(address_2),
                at_date = VALUES(at_date),
                birth_date = VALUES(birth_date),
                name = VALUES(name),
                issue_date = VALUES(issue_date),
                page_number = VALUES(page_number)
            """
        )
        cursor.execute(sql, (rn, address_1, address_2, at_date, birth_date, name, issue_date, page_number_json))
        conn.commit()
        return True
    except Exception as e:
        print(f"âŒ MySQL ì €ì¥ ì‹¤íŒ¨(ì´ˆë³¸) {rn}: {e}")
        try:
            if conn and conn.is_connected():
                conn.rollback()
        except Exception:
            pass
        return False
    finally:
        try:
            if conn and conn.is_connected():
                conn.close()
        except Exception:
            pass


def gemini_worker_thread():
    """Gemini íë¥¼ ê°ì‹œí•˜ê³  ë¬¸ì„œ íŒë‹¨ ìˆ˜í–‰ (êµ¬ë§¤ê³„ì•½ì„œ/ì´ˆë³¸)"""
    print("ğŸš€ Gemini ì›Œì»¤ ìŠ¤ë ˆë“œ ì‹œì‘")
    try:
        client = genai.Client(api_key=API_KEY)
    except Exception as e:
        print(f"âŒ Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return

    while True:
        try:
            task = gemini_queue.get()
            rn = task.get('rn')
            pdf_path = task.get('pdf_path')
            if not (rn and pdf_path and os.path.exists(pdf_path)):
                gemini_queue.task_done()
                continue

            print(f"ğŸ¤– Gemini ì²˜ë¦¬ ì‹œì‘: {rn} â†’ {pdf_path}")

            pdf_bytes = pathlib.Path(pdf_path).read_bytes()

            def _call(prompt_text, parse_func):
                response = client.models.generate_content(
                    model="gemini-2.5-flash",
                    contents=[
                        types.Part.from_bytes(data=pdf_bytes, mime_type='application/pdf'),
                        prompt_text,
                    ],
                )
                if parse_func is parse_response_contract:
                    order_date, vehicle_config, customer_name, extracted_rn, phone_number, email, page_number = parse_func(response.text)
                    return {
                        'order_date': order_date,
                        'vehicle_config': vehicle_config,
                        'customer_name': customer_name,
                        'rn': extracted_rn,
                        'phone_number': phone_number,
                        'email': email,
                        'page_number': page_number,
                    }
                else:
                    return parse_func(response.text)

            # ë‘ ì‘ì—… ë³‘ë ¬ ì‹¤í–‰ (êµ¬ë§¤ê³„ì•½ì„œ, ì´ˆë³¸)
            from concurrent.futures import ThreadPoolExecutor
            results = {}

            with ThreadPoolExecutor(max_workers=2) as ex:
                futures = {
                    ex.submit(_call, prompt_contract, parse_response_contract): 'contract',
                    ex.submit(_call, prompt_resident_cert, parse_response_resident_cert): 'resident',
                }
                for fut in futures:
                    key = futures[fut]
                    try:
                        results[key] = fut.result()
                    except Exception as e:
                        print(f"  âš ï¸ Gemini í˜¸ì¶œ ì‹¤íŒ¨({key}): {e}")
                        results[key] = None

            # ì €ì¥ (ë®ì–´ì“°ê¸°)
            if results.get('contract') is not None:
                save_contract_to_mysql(rn, results['contract'])
            if results.get('resident') is not None:
                save_resident_cert_to_mysql(rn, results['resident'])

            print(f"âœ… Gemini ì²˜ë¦¬ ì™„ë£Œ: {rn}")

        except Exception as e:
            print(f"âŒ Gemini ì›Œì»¤ ì˜ˆì™¸: {e}")
        finally:
            try:
                gemini_queue.task_done()
            except Exception:
                pass

def merge_and_preprocess_pdfs(pdf_paths: list, processed_dir: str, thread_id: str) -> str | None:
    """ì—¬ëŸ¬ PDF íŒŒì¼ì„ í•˜ë‚˜ë¡œ ë³‘í•©í•˜ê³  ìµœì í™” (ë²¡í„° ìœ ì§€)
    
    Args:
        pdf_paths: ë³‘í•©í•  PDF íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        processed_dir: ì²˜ë¦¬ëœ íŒŒì¼ì„ ì €ì¥í•  ë””ë ‰í† ë¦¬
        thread_id: ë©”ì¼ ìŠ¤ë ˆë“œ ID (íŒŒì¼ëª… ìƒì„±ìš©)
    
    Returns:
        ë³‘í•© ë° ìµœì í™”ëœ PDF íŒŒì¼ ê²½ë¡œ (ì‹¤íŒ¨ ì‹œ None)
    """
    try:
        from pathlib import Path
        import pymupdf
        
        if not pdf_paths:
            return None
        
        # ë‹¨ì¼ íŒŒì¼ì¸ ê²½ìš° ê¸°ì¡´ í•¨ìˆ˜ ì‚¬ìš©
        if len(pdf_paths) == 1:
            return preprocess_pdf_for_rendering(pdf_paths[0], processed_dir)
        
        # ë³‘í•©ëœ íŒŒì¼ëª… ìƒì„±: thread_id ê¸°ë°˜
        merged_filename = f"{thread_id}_merged_processed.pdf"
        merged_path = os.path.join(processed_dir, merged_filename)
        
        # ì´ë¯¸ ì²˜ë¦¬ëœ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
        if os.path.exists(merged_path):
            # ëª¨ë“  ì›ë³¸ íŒŒì¼ë³´ë‹¤ ìµœì‹ ì¸ì§€ í™•ì¸
            merged_mtime = os.path.getmtime(merged_path)
            if all(merged_mtime >= os.path.getmtime(p) for p in pdf_paths if os.path.exists(p)):
                print(f"  âš¡ ì´ë¯¸ ë³‘í•© ì „ì²˜ë¦¬ë¨: {merged_filename}")
                return merged_path
        
        print(f"  ğŸ”§ {len(pdf_paths)}ê°œ PDF ë³‘í•© ë° ìµœì í™” ì¤‘...")
        
        # ë³‘í•© ë° A4 ìµœì í™”
        merged_doc = pymupdf.open()
        
        for idx, pdf_path in enumerate(pdf_paths):
            print(f"    - [{idx+1}/{len(pdf_paths)}] {os.path.basename(pdf_path)}")
            
            try:
                with pymupdf.open(pdf_path) as source_doc:
                    # ê° í˜ì´ì§€ë¥¼ A4ë¡œ ë³€í™˜í•˜ì—¬ ë³‘í•©
                    for page_num in range(len(source_doc)):
                        page = source_doc[page_num]
                        bounds = page.bound()
                        is_landscape = bounds.width > bounds.height
                        
                        if is_landscape:
                            a4_rect = pymupdf.paper_rect("a4-l")
                        else:
                            a4_rect = pymupdf.paper_rect("a4")
                        
                        # ìƒˆ A4 í˜ì´ì§€ ìƒì„±
                        new_page = merged_doc.new_page(width=a4_rect.width, height=a4_rect.height)
                        
                        # ë²¡í„° ê¸°ë°˜ìœ¼ë¡œ í˜ì´ì§€ ë³µì‚¬
                        new_page.show_pdf_page(new_page.rect, source_doc, page_num)
            
            except Exception as e:
                print(f"    âš ï¸ íŒŒì¼ ë³‘í•© ì‹¤íŒ¨: {os.path.basename(pdf_path)} - {e}")
                continue
        
        # ë³‘í•©ëœ PDF ì €ì¥ (ìµœì í™”)
        merged_doc.save(
            merged_path,
            garbage=4,
            deflate=True,
            clean=True,
            pretty=False,
            linear=False,
        )
        merged_doc.close()
        
        print(f"  âœ… ë³‘í•© ì™„ë£Œ: {merged_filename}")
        return merged_path
        
    except Exception as e:
        print(f"  âš ï¸ ë³‘í•© ë° ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return None


def preprocess_pdf_for_rendering(original_path: str, processed_dir: str) -> str | None:
    """PDFë¥¼ ë Œë”ë§ì— ìµœì í™”ëœ í˜•íƒœë¡œ ì „ì²˜ë¦¬ (3MB ì´ˆê³¼ íŒŒì¼ìš©)
    
    ì „ëµ: ë²¡í„° ê¸°ë°˜ í˜ì´ì§€ëŠ” ê·¸ëŒ€ë¡œ ë³µì‚¬, ì´ë¯¸ì§€ê°€ ë§ì€ í˜ì´ì§€ë§Œ ìµœì í™”
    """
    try:
        from pathlib import Path
        import pymupdf
        
        # íŒŒì¼ëª… ìƒì„±
        base_name = Path(original_path).stem
        processed_filename = f"{base_name}_processed.pdf"
        processed_path = os.path.join(processed_dir, processed_filename)
        
        # ì´ë¯¸ ì²˜ë¦¬ëœ íŒŒì¼ì´ ìˆê³  ìµœì‹ ì´ë©´ ìŠ¤í‚µ
        if os.path.exists(processed_path):
            if os.path.getmtime(processed_path) >= os.path.getmtime(original_path):
                print(f"  âš¡ ì´ë¯¸ ì „ì²˜ë¦¬ë¨: {processed_filename}")
                return processed_path
        
        print(f"  ğŸ”§ PDF ìµœì í™” ì¤‘: {base_name}")
        
        # ë‹¨ìˆœ ìµœì í™”: garbage collection + deflate + clean
        # ë²¡í„° ë°ì´í„°ëŠ” ìœ ì§€í•˜ë©´ì„œ ë¶ˆí•„ìš”í•œ ê°ì²´ë§Œ ì œê±°
        with pymupdf.open(original_path) as source_doc:
            # A4 ê·œê²©ìœ¼ë¡œ ë³€í™˜í•˜ë˜, ë²¡í„° ë°ì´í„°ë¥¼ ìœ ì§€í•˜ëŠ” ë°©ì‹
            new_doc = pymupdf.open()
            
            for page_num in range(len(source_doc)):
                page = source_doc[page_num]
                bounds = page.bound()
                is_landscape = bounds.width > bounds.height
                
                if is_landscape:
                    a4_rect = pymupdf.paper_rect("a4-l")
                else:
                    a4_rect = pymupdf.paper_rect("a4")
                
                # ìƒˆ A4 í˜ì´ì§€ ìƒì„±
                new_page = new_doc.new_page(width=a4_rect.width, height=a4_rect.height)
                
                # show_pdf_page: ë²¡í„° ê¸°ë°˜ìœ¼ë¡œ í˜ì´ì§€ë¥¼ ë³µì‚¬ (ì´ë¯¸ì§€ë¡œ ë³€í™˜í•˜ì§€ ì•ŠìŒ)
                new_page.show_pdf_page(new_page.rect, source_doc, page_num)
            
            # ê°•ë ¥í•œ ìµœì í™” ì˜µì…˜ìœ¼ë¡œ ì €ì¥
            new_doc.save(
                processed_path,
                garbage=4,          # ìµœëŒ€ garbage collection
                deflate=True,       # ì••ì¶• í™œì„±í™”
                clean=True,         # ë¶ˆí•„ìš”í•œ ê°ì²´ ì œê±°
                pretty=False,       # ê°€ë…ì„± ì œê±° (í¬ê¸° ê°ì†Œ)
                linear=False,       # ì„ í˜•í™” ë¹„í™œì„±í™” (ì›¹ ìµœì í™” ë¶ˆí•„ìš”)
            )
            new_doc.close()
        
        return processed_path
        
    except Exception as e:
        print(f"  âš ï¸ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return None


if __name__ == "__main__":
    print("="*50)
    print(" ë©”ì¼ ìˆ˜ì§‘ ë° ì²¨ë¶€íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì„œë¹„ìŠ¤ ì‹œì‘")
    print(f" ì „ì²˜ë¦¬ ì„ê³„ê°’: {PREPROCESS_THRESHOLD_MB} MB ì´ˆê³¼")
    print("="*50)

    # ìµœì´ˆ ì‹¤í–‰ ê²€ì‚¬
    INITIAL_RUN_FLAG = 'initial_run.flag'
    if not os.path.exists(INITIAL_RUN_FLAG):
        initial_email_check()
        # í”Œë˜ê·¸ íŒŒì¼ ìƒì„±
        try:
            with open(INITIAL_RUN_FLAG, 'w') as f:
                f.write(f"Initial run completed at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        except Exception as e:
            print(f"âš ï¸ í”Œë˜ê·¸ íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")

    # 1. ë©”ì¼ ìˆ˜ì§‘ ìŠ¤ë ˆë“œ (20ì´ˆ ì£¼ê¸°)
    mail_collector = threading.Thread(target=db_mail_thread, daemon=True)
    mail_collector.start()

    # 2. ë‹¤ìš´ë¡œë“œ ì›Œì»¤ ìŠ¤ë ˆë“œ
    attachment_downloader = threading.Thread(target=download_worker_thread, daemon=True)
    attachment_downloader.start()

    # 3. ì „ì²˜ë¦¬ ì›Œì»¤ ìŠ¤ë ˆë“œ (ìƒˆë¡œ ì¶”ê°€!)
    pdf_preprocessor = threading.Thread(target=preprocess_worker_thread, daemon=True)
    pdf_preprocessor.start()

    # 4. Gemini ì›Œì»¤ ìŠ¤ë ˆë“œ (ì‹ ê·œ)
    gemini_processor = threading.Thread(target=gemini_worker_thread, daemon=True)
    gemini_processor.start()

    # ë©”ì¸ ìŠ¤ë ˆë“œëŠ” ë°ëª¬ ìŠ¤ë ˆë“œê°€ ì¢…ë£Œë˜ì§€ ì•Šë„ë¡ ìœ ì§€
    try:
        # ìŠ¤ë ˆë“œê°€ ì‚´ì•„ìˆëŠ”ì§€ ì£¼ê¸°ì ìœ¼ë¡œ í™•ì¸
        while (mail_collector.is_alive() and 
               attachment_downloader.is_alive() and 
               pdf_preprocessor.is_alive() and 
               gemini_processor.is_alive()):
            time.sleep(1)
    except KeyboardInterrupt:
        print("\nğŸš« ì„œë¹„ìŠ¤ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
