import os
import re
import base64
import time
import tempfile
import threading
from queue import Queue
from datetime import datetime, timedelta

import mysql.connector
from mysql.connector import Error
import pytz
from filelock import FileLock

from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
from google.auth.transport.requests import Request

# --- ì „ì—­ ì„¤ì • ---
SCOPES = ['https://www.googleapis.com/auth/gmail.modify']
MYSQL_CONFIG = {
    'host': '192.168.0.114',
    'port': 3306,
    'user': 'my_pc_user',
    'password': '!Qdhdbrclf56',
    'database': 'greetlounge',
    'charset': 'utf8mb4'
}
CREDENTIALS_FILE = 'credentials_3.json'
TOKEN_FILE = 'token123.json'
ATTACHMENT_SAVE_DIR = "C:\\Users\\HP\\Desktop\\greet_db\\files\\new"

# ìŠ¤ë ˆë“œ ê°„ í†µì‹ ì„ ìœ„í•œ ê³µìœ  í
download_queue = Queue()
preprocess_queue = Queue()  # ì „ì²˜ë¦¬ í ì¶”ê°€

# ì „ì²˜ë¦¬ ì„ê³„ê°’ ì„¤ì •
PREPROCESS_THRESHOLD_MB = 3.0  # 3MB ì´ˆê³¼ ì‹œì—ë§Œ ì „ì²˜ë¦¬
PROCESSED_DIR = "C:\\Users\\HP\\Desktop\\greet_db\\files\\processed"

# --- DB ë° Gmail API ì—°ê²° ---

def get_database_connection():
    """MySQL ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë°˜í™˜ (ìŠ¤ë ˆë“œë³„ë¡œ í˜¸ì¶œ)"""
    try:
        conn = mysql.connector.connect(**MYSQL_CONFIG)
        return conn
    except Error as e:
        print(f"âŒ MySQL ì—°ê²° ì‹¤íŒ¨: {e}")
        return None

def get_service(credentials_file, token_file):
    """Gmail ì„œë¹„ìŠ¤ ì¸ì¦ (í† í° íŒŒì¼ ì ê¸ˆ ê¸°ëŠ¥ ì¶”ê°€)"""
    creds = None
    token_lock_file = f"{token_file}.lock"
    lock = FileLock(token_lock_file)

    with lock:
        if os.path.exists(token_file):
            creds = Credentials.from_authorized_user_file(token_file, SCOPES)
        
        if not creds or not creds.valid:
            if creds and creds.expired and creds.refresh_token:
                print("ğŸ”„ Gmail í† í° ê°±ì‹  ì¤‘...")
                creds.refresh(Request())
            else:
                flow = InstalledAppFlow.from_client_secrets_file(credentials_file, SCOPES)
                creds = flow.run_local_server(port=0)
            
            with open(token_file, 'w') as token:
                token.write(creds.to_json())
    
    try:
        service = build('gmail', 'v1', credentials=creds)
        print("âœ… Gmail ì„œë¹„ìŠ¤ ì¸ì¦ ì„±ê³µ")
        return service
    except Exception as e:
        print(f"âŒ Gmail ì„œë¹„ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")
        return None

# --- ë©”ì¼ ìˆ˜ì§‘ ìŠ¤ë ˆë“œ(db_mail_thread)ìš© í•¨ìˆ˜ ---

def has_attachment(payload):
    """ì²¨ë¶€íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ë§Œ ë¹ ë¥´ê²Œ í™•ì¸ (ë‹¤ìš´ë¡œë“œ ì•ˆí•¨)"""
    if 'parts' in payload:
        for part in payload['parts']:
            if part.get('filename') or part.get('body', {}).get('attachmentId'):
                return True
            # ì¬ê·€ì ìœ¼ë¡œ ë‚´ë¶€ partë„ í™•ì¸
            if 'parts' in part and has_attachment(part):
                return True
    if payload.get('body', {}).get('attachmentId'):
        return True
    return False

def save_email_to_db(conn, thread_id, title, content, from_address, received_date, has_attach):
    """emails í…Œì´ë¸”ì— ë©”ì¼ ì •ë³´ ì €ì¥"""
    # (db_mail.pyì˜ save_email_to_db í•¨ìˆ˜ì™€ ë™ì¼)
    cursor = conn.cursor()
    try:
        sql = """
            INSERT INTO emails (thread_id, received_date, from_email_address, title, content, attached_file)
            VALUES (%s, %s, %s, %s, %s, %s)
            ON DUPLICATE KEY UPDATE 
                received_date=VALUES(received_date), from_email_address=VALUES(from_email_address),
                title=VALUES(title), content=VALUES(content), attached_file=VALUES(attached_file)
        """
        cursor.execute(sql, (thread_id, received_date, from_address, title, content, 1 if has_attach else 0))
        # print(f"âœ… (DB) ë©”ì¼ ì •ë³´ ì €ì¥: {thread_id}")
        return True
    except Error as e:
        print(f"âŒ (DB) ë©”ì¼ ì •ë³´ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def insert_new_application(conn, rn, received_date, thread_id, region, delivery_date, name, special_note):
    """subsidy_applications í…Œì´ë¸”ì— ì‹ ê·œ ì‹ ì²­ ê±´ ì‚½ì…"""
    # (db_mail.pyì˜ insert_new_application í•¨ìˆ˜ì™€ ë™ì¼, region NULL ì²˜ë¦¬ í¬í•¨)
    cursor = conn.cursor()
    try:
        sql = """
            INSERT INTO subsidy_applications 
            (RN, mail_count, recent_received_date, recent_thread_id, region, delivery_date, name, special_note, status, status_updated_at)
            VALUES (%s, 1, %s, %s, %s, %s, %s, %s, 'ì‹ ê·œ', %s)
        """
        if not delivery_date: delivery_date = None
        if not region: region = None
        now_kst = datetime.now(pytz.timezone('Asia/Seoul')).strftime('%Y-%m-%d %H:%M:%S')
        cursor.execute(sql, (rn, received_date, thread_id, region, delivery_date, name, special_note, now_kst))
        # print(f"âœ… (DB) ì‹ ê·œ ì‹ ì²­ ê±´ ì €ì¥: {rn}")
        return True
    except Error as e:
        print(f"âŒ (DB) ì‹ ê·œ ì‹ ì²­ ê±´ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def update_duplicate_application(conn, rn, new_thread_id, new_received_date):
    """ì¤‘ë³µ RN ì—…ë°ì´íŠ¸"""
    # (db_mail.pyì˜ update_duplicate_application í•¨ìˆ˜ì™€ ë™ì¼)
    cursor = conn.cursor()
    try:
        update_sql = "UPDATE subsidy_applications SET mail_count = mail_count + 1, recent_received_date = %s, recent_thread_id = %s WHERE RN = %s"
        cursor.execute(update_sql, (new_received_date, new_thread_id, rn))
        insert_sql = "INSERT INTO duplicated_rn (thread_id, RN, received_date) VALUES (%s, %s, %s)"
        cursor.execute(insert_sql, (new_thread_id, rn, new_received_date))
        # print(f"âœ… (DB) ì¤‘ë³µ ì‹ ì²­ ê±´ ì—…ë°ì´íŠ¸: {rn}")
        return True
    except Error as e:
        print(f"âŒ (DB) ì¤‘ë³µ ì‹ ì²­ ê±´ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
        return False

# --- ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ---
# (db_mail.pyì˜ í•¨ìˆ˜ë“¤, ì¼ë¶€ëŠ” ê°„ì†Œí™”)
def get_existing_rn_numbers(conn):
    cursor = conn.cursor()
    cursor.execute('SELECT RN FROM subsidy_applications')
    return {row[0] for row in cursor.fetchall()}

def get_label_id(service, label_name='RNë¶™ì„'):
    results = service.users().labels().list(userId='me').execute()
    labels = results.get('labels', [])
    return next((label['id'] for label in labels if label['name'] == label_name), None)

def safe_modify_message(service, msg_id, label_id):
    try:
        service.users().messages().modify(userId='me', id=msg_id, body={'addLabelIds': [label_id]}).execute()
        return True
    except Exception as e:
        print(f"âš ï¸ ë¼ë²¨ ì¶”ê°€ ì‹¤íŒ¨: {e}")
        return False

def extract_text_from_payload(payload):
    if 'parts' in payload:
        for part in payload['parts']:
            result = extract_text_from_payload(part)
            if result: return result
    elif payload.get('mimeType') in ['text/plain', 'text/html']:
        data = payload.get('body', {}).get('data', '')
        if data:
            try:
                text = base64.urlsafe_b64decode(data).decode('utf-8')
                if payload['mimeType'] == 'text/html':
                    text = re.sub(r'<[^>]+>', '', text)
                return re.sub(r'[ \t]+', ' ', text).strip()[:1000]
            except: return "ë‚´ìš© ë””ì½”ë”© ì‹¤íŒ¨"
    return ""

def extract_info_from_subject(subject):
    rn_match = re.search(r'RN\d{9}', subject)
    if not rn_match: return None
    rn_num = rn_match.group()
    date_match = re.search(r'\[(\d{1,2})/(\d{1,2})\]', subject)
    date_str = f'2025-{int(date_match.group(1)):02d}-{int(date_match.group(2)):02d}' if date_match else None
    region_match = re.search(r'RN\d{9}\s*/\s*([^/]+)', subject)
    region = region_match.group(1).strip() if region_match else None
    if region and any(word in region for word in ['ë¦¬ìŠ¤', 'ìºí”¼íƒˆ']): region = 'í•œêµ­í™˜ê²½ê³µë‹¨'
    applier = None
    try:
        parts = [p.strip() for p in subject.split('/')]
        model_index = next((i for i, part in enumerate(parts) if 'Model' in part), -1)
        if model_index != -1 and model_index + 1 < len(parts) and parts[model_index + 1]:
            applier = parts[model_index + 1]
    except: pass
    return {'rn_num': rn_num, 'date': date_str, 'region': region, 'applier': applier}

def extract_special_note_from_content(content):
    if not content: return ''
    patterns = [r'\d+\.\s*íŠ¹ì´ì‚¬í•­\s*:\s*([^\n\r]+)', r'íŠ¹ì´ì‚¬í•­\s*:\s*([^\n\r]+)', r'íŠ¹ì´ì‚¬í•­\s+([^\n\r]+)']
    for p in patterns:
        match = re.search(p, content)
        if match: return match.group(1).strip()
    return ''

def parsing_special(text):
    return '' if text.startswith('ê°ì‚¬') else text

# --- ë‹¤ìš´ë¡œë“œ ì›Œì»¤ ìŠ¤ë ˆë“œ(download_worker_thread)ìš© í•¨ìˆ˜ ---

def download_attachment(gmail_service, msg_id, part, save_dir, new_filename=None):
    """ë‹¨ì¼ ì²¨ë¶€íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
    try:
        filename = part.get('filename', '')
        if not filename: return None
        if 'attachmentId' in part.get('body', {}):
            attachment_id = part['body']['attachmentId']
            attachment = gmail_service.users().messages().attachments().get(
                userId='me', messageId=msg_id, id=attachment_id
            ).execute()
            file_data = base64.urlsafe_b64decode(attachment['data'])
            
            # ìƒˆ íŒŒì¼ëª…ì´ ì§€ì •ëœ ê²½ìš° ì‚¬ìš©, ì•„ë‹ˆë©´ ì›ë³¸ íŒŒì¼ëª… ì‚¬ìš©
            if new_filename:
                # ì›ë³¸ íŒŒì¼ì˜ í™•ì¥ì ìœ ì§€
                _, ext = os.path.splitext(filename)
                final_filename = f"{new_filename}{ext}"
            else:
                base_name, ext = os.path.splitext(filename)
                final_filename = filename
            
            # íŒŒì¼ëª… ì¤‘ë³µ ë°©ì§€
            counter = 1
            temp_filename = final_filename
            while os.path.exists(os.path.join(save_dir, temp_filename)):
                if new_filename:
                    temp_filename = f"{new_filename}_{counter}{ext}"
                else:
                    temp_filename = f"{base_name}_{counter}{ext}"
                counter += 1
            final_filename = temp_filename
            
            file_path = os.path.join(save_dir, final_filename)
            with open(file_path, 'wb') as f: f.write(file_data)
            print(f"  â¡ï¸ íŒŒì¼ ì €ì¥: {file_path}")
            return file_path
        return None
    except Exception as e:
        print(f"  âš ï¸ ì²¨ë¶€íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

def download_and_process_attachments(gmail_service, msg_id, payload, thread_id, save_dir, subject):
    """payloadì—ì„œ ëª¨ë“  ì²¨ë¶€íŒŒì¼ì„ ì°¾ì•„ ë‹¤ìš´ë¡œë“œí•˜ê³  í•„ìš”ì‹œ ë³‘í•©"""
    # (db_mail.pyì˜ check_attached_file ë¡œì§ì„ ì¬êµ¬ì„±)
    if not os.path.exists(save_dir): os.makedirs(save_dir)
    
    # ì œëª©ì—ì„œ RN, name, region ì¶”ì¶œ
    info = extract_info_from_subject(subject)
    new_filename = None
    
    if info and info.get('rn_num'):
        # {RN}_{name}_{region} í˜•ì‹ìœ¼ë¡œ íŒŒì¼ëª… ìƒì„±
        parts = [info['rn_num']]
        if info.get('applier'):
            parts.append(info['applier'])
        if info.get('region'):
            parts.append(info['region'])
        new_filename = '_'.join(parts)
        print(f"  ğŸ“ ìƒˆ íŒŒì¼ëª…: {new_filename}")
    
    attachment_paths = []
    
    def find_attachments_recursive(part_or_payload):
        """ì¬ê·€ì ìœ¼ë¡œ ì²¨ë¶€íŒŒì¼ partë¥¼ ì°¾ì•„ì„œ ë‹¤ìš´ë¡œë“œ"""
        if 'parts' in part_or_payload:
            for sub_part in part_or_payload['parts']:
                find_attachments_recursive(sub_part)
        
        if part_or_payload.get('filename') or part_or_payload.get('body', {}).get('attachmentId'):
            file_path = download_attachment(gmail_service, msg_id, part_or_payload, save_dir, new_filename)
            if file_path:
                attachment_paths.append(file_path)

    find_attachments_recursive(payload)

    if not attachment_paths: return 'N'
    
    unique_paths = list(set(attachment_paths))
    
    # PDF ë³‘í•© ë¡œì§ì€ ìƒëµ (í•„ìš” ì‹œ db_mail.pyì—ì„œ ê°€ì ¸ì™€ ì¶”ê°€)
    # í˜„ì¬ëŠ” íŒŒì¼ ê²½ë¡œë¥¼ ì„¸ë¯¸ì½œë¡ ìœ¼ë¡œ ì—°ê²°í•˜ì—¬ ë°˜í™˜
    return ';'.join(unique_paths)

def update_email_attachment_path(conn, thread_id, file_path, file_rendered=0):
    """emails í…Œì´ë¸”ì— ìµœì¢… ì²¨ë¶€íŒŒì¼ ê²½ë¡œ ì—…ë°ì´íŠ¸ ë° file_rendered ì„¤ì •"""
    cursor = conn.cursor()
    try:
        sql = """UPDATE emails 
                 SET attached_file = 1, 
                     attached_file_path = %s,
                     file_rendered = %s
                 WHERE thread_id = %s"""
        cursor.execute(sql, (file_path, file_rendered, thread_id))
        conn.commit()
        print(f"  âœ… (DB) ì²¨ë¶€íŒŒì¼ ì •ë³´ ì €ì¥: {thread_id} (file_rendered={file_rendered})")
    except Error as e:
        print(f"  âŒ (DB) ì²¨ë¶€íŒŒì¼ ê²½ë¡œ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
        conn.rollback()

# --- ìŠ¤ë ˆë“œ ë©”ì¸ í•¨ìˆ˜ ---

def db_mail_thread(poll_interval=20):
    """20ì´ˆë§ˆë‹¤ ìƒˆ ë©”ì¼ì„ í™•ì¸í•˜ê³  DBì— ì €ì¥, ë‹¤ìš´ë¡œë“œ íì— ì¶”ê°€"""
    print("ğŸš€ ë©”ì¼ ìˆ˜ì§‘ ìŠ¤ë ˆë“œ ì‹œì‘")
    gmail_service = get_service(CREDENTIALS_FILE, TOKEN_FILE)
    if not gmail_service: return
    
    label_id = get_label_id(gmail_service)
    if not label_id:
        print("âŒ 'RNë¶™ì„' ë¼ë²¨ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìŠ¤ë ˆë“œë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    while True:
        print(f"\n--- {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} ---")
        print("ğŸ“¬ ìƒˆ ë©”ì¼ í™•ì¸ ì¤‘...")
        
        conn = get_database_connection()
        if not conn:
            time.sleep(poll_interval)
            continue

        try:
            results = gmail_service.users().messages().list(
                userId='me', q='newer_than:2h -label:RNë¶™ì„', maxResults=25
            ).execute()
            messages = results.get('messages', [])

            if not messages:
                print("âœ… ì²˜ë¦¬í•  ìƒˆ ë©”ì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            else:
                print(f"ğŸ” {len(messages)}ê°œì˜ ìƒˆ ë©”ì¼ ìŠ¤ë ˆë“œ ë°œê²¬. ì²˜ë¦¬ ì‹œì‘...")
                existing_rns = get_existing_rn_numbers(conn)
                
                for msg in reversed(messages):
                    try:
                        msg_detail = gmail_service.users().messages().get(
                            userId='me', id=msg['id'], format='full'
                        ).execute()
                        
                        if msg_detail['id'] != msg_detail['threadId']: continue

                        payload = msg_detail.get('payload', {})
                        headers = payload.get('headers', [])
                        subject = next((h['value'] for h in headers if h['name'].lower() == 'subject'), '')
                        thread_id = msg_detail['threadId']
                        
                        # 1. ë©”ì¼ ì •ë³´ ì¶”ì¶œ ë° DB ì €ì¥
                        content = extract_text_from_payload(payload)
                        ts = int(msg_detail.get('internalDate')) / 1000
                        received_dt = datetime.fromtimestamp(ts, pytz.timezone('Asia/Seoul')).strftime('%Y-%m-%d %H:%M:%S')
                        from_header = next((h['value'] for h in headers if h['name'].lower() == 'from'), '')
                        from_address = re.search(r'<(.+?)>', from_header).group(1) if re.search(r'<(.+?)>', from_header) else from_header

                        has_attach = has_attachment(payload)
                        save_email_to_db(conn, thread_id, subject, content, from_address, received_dt, False)  # ë‹¤ìš´ë¡œë“œ ì™„ë£Œ ì „ê¹Œì§€ 0

                        # 2. RN ì •ë³´ ì¶”ì¶œ ë° subsidy_applications ì €ì¥
                        info = extract_info_from_subject(subject)
                        if info and info.get('rn_num'):
                            rn_num = info['rn_num']
                            special_note = parsing_special(extract_special_note_from_content(content))
                            
                            if rn_num in existing_rns:
                                update_duplicate_application(conn, rn_num, thread_id, received_dt)
                            else:
                                insert_new_application(conn, rn_num, received_dt, thread_id, info.get('region'), info.get('date'), info.get('applier'), special_note)
                                existing_rns.add(rn_num)
                        
                        # 3. ë¼ë²¨ ë¶€ì°©
                        safe_modify_message(gmail_service, msg['id'], label_id)

                        # 4. ì²¨ë¶€íŒŒì¼ì´ ìˆìœ¼ë©´ ë‹¤ìš´ë¡œë“œ íì— ì¶”ê°€
                        if has_attach:
                            download_queue.put({
                                'msg_id': msg['id'],
                                'thread_id': thread_id,
                            })
                            print(f"ğŸ“ ë‹¤ìš´ë¡œë“œ íì— ì¶”ê°€: {thread_id}")

                    except HttpError as e:
                        if e.resp.status == 404: print(f"âš ï¸ 404 - ì‚­ì œëœ ë©”ì¼: {msg['id']}")
                        else: print(f"âŒ HTTP ì˜¤ë¥˜: {e}")
                    except Exception as e:
                        print(f"âŒ ë©”ì¼ ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
                
                conn.commit()
                print("ğŸ‰ ë©”ì¼ ì²˜ë¦¬ ì™„ë£Œ.")

        except Exception as e:
            print(f"âŒ ë©”ì¸ ë£¨í”„ ì˜¤ë¥˜: {e}")
            if conn.is_connected(): conn.rollback()
        finally:
            if conn.is_connected(): conn.close()

        print(f"â° {poll_interval}ì´ˆ í›„ì— ë‹¤ì‹œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
        time.sleep(poll_interval)

def download_worker_thread():
    """ë‹¤ìš´ë¡œë“œ íë¥¼ ê°ì‹œí•˜ê³  ì²¨ë¶€íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œ (ì „ì²˜ë¦¬ëŠ” ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ)"""
    print("ğŸš€ ë‹¤ìš´ë¡œë“œ ì›Œì»¤ ìŠ¤ë ˆë“œ ì‹œì‘")
    gmail_service = get_service(CREDENTIALS_FILE, TOKEN_FILE)
    if not gmail_service: return

    while True:
        try:
            task = download_queue.get()
            msg_id = task['msg_id']
            thread_id = task['thread_id']
            
            print(f"â¬‡ï¸ ë‹¤ìš´ë¡œë“œ ì‹œì‘: {thread_id}")

            conn = get_database_connection()
            if not conn:
                # DB ì—°ê²° ì‹¤íŒ¨ ì‹œ ì‘ì—…ì„ ë‹¤ì‹œ íì— ë„£ê³  ëŒ€ê¸°
                print("  âš ï¸ DB ì—°ê²° ì‹¤íŒ¨. ì‘ì—…ì„ íì— ë‹¤ì‹œ ì¶”ê°€í•©ë‹ˆë‹¤.")
                download_queue.put(task)
                time.sleep(10)
                continue

            try:
                msg_detail = gmail_service.users().messages().get(
                    userId='me', id=msg_id, format='full'
                ).execute()
                payload = msg_detail.get('payload', {})
                headers = payload.get('headers', [])
                subject = next((h['value'] for h in headers if h['name'].lower() == 'subject'), '')
                
                # ë‹¤ìš´ë¡œë“œ ìˆ˜í–‰
                final_path = download_and_process_attachments(
                    gmail_service, msg_id, payload, thread_id, ATTACHMENT_SAVE_DIR, subject
                )
                
                if final_path != 'N':
                    # ì„¸ë¯¸ì½œë¡ ìœ¼ë¡œ êµ¬ë¶„ëœ ì—¬ëŸ¬ íŒŒì¼ í™•ì¸
                    file_paths = final_path.split(';')
                    file_paths = [p.strip() for p in file_paths if p.strip()]
                    
                    # PDF íŒŒì¼ë“¤ë§Œ í•„í„°ë§
                    pdf_files = [p for p in file_paths if p.lower().endswith('.pdf')]
                    
                    # ì „ì²´ ìš©ëŸ‰ ê³„ì‚° (PDFë§Œ)
                    total_size_mb = sum(os.path.getsize(p) / (1024 * 1024) for p in pdf_files)
                    
                    needs_preprocess = False
                    
                    # PDFê°€ 1ê°œ ì´ìƒì´ê³  ì „ì²´ ìš©ëŸ‰ì´ 3MB ì´ˆê³¼ ì‹œ ì „ì²˜ë¦¬ í•„ìš”
                    if pdf_files and total_size_mb > PREPROCESS_THRESHOLD_MB:
                        needs_preprocess = True
                        print(f"  ğŸ“ PDF íŒŒì¼ {len(pdf_files)}ê°œ, ì´ í¬ê¸°: {total_size_mb:.2f} MB â†’ ì „ì²˜ë¦¬ í•„ìš”")
                        
                        # ì „ì²˜ë¦¬ íì— ì¶”ê°€ (ì—¬ëŸ¬ íŒŒì¼ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ì „ë‹¬)
                        preprocess_queue.put({
                            'thread_id': thread_id,
                            'original_paths': pdf_files  # ì—¬ëŸ¬ íŒŒì¼ì„ ë¦¬ìŠ¤íŠ¸ë¡œ
                        })
                        print(f"  ğŸ“‹ ì „ì²˜ë¦¬ íì— ì¶”ê°€: {len(pdf_files)}ê°œ íŒŒì¼ ë³‘í•© ì˜ˆì •")
                    else:
                        if pdf_files:
                            print(f"  ğŸ“ PDF íŒŒì¼ {len(pdf_files)}ê°œ, ì´ í¬ê¸°: {total_size_mb:.2f} MB â†’ ì „ì²˜ë¦¬ ë¶ˆí•„ìš”")
                        else:
                            print(f"  ğŸ“ PDF íŒŒì¼ ì—†ìŒ â†’ ì „ì²˜ë¦¬ ë¶ˆí•„ìš”")
                    
                    # DB ì—…ë°ì´íŠ¸: file_rendered = 0 (ì•„ì§ ì „ì²˜ë¦¬ ì•ˆë¨)
                    final_paths_str = ';'.join(file_paths)
                    update_email_attachment_path(conn, thread_id, final_paths_str, file_rendered=0)
                
                print(f"âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {thread_id}")

            except Exception as e:
                print(f"âŒ ë‹¤ìš´ë¡œë“œ ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {thread_id}, {e}")
            finally:
                if conn.is_connected(): conn.close()
                download_queue.task_done()

        except Exception as e:
            # í ìì²´ì˜ ë¬¸ì œ ë“± ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜
            print(f"âŒ ì›Œì»¤ ìŠ¤ë ˆë“œ ì˜¤ë¥˜: {e}")
            time.sleep(5)


def preprocess_worker_thread():
    """âœ¨ ì „ì²˜ë¦¬ íë¥¼ ê°ì‹œí•˜ê³  ëŒ€ìš©ëŸ‰ PDF ìµœì í™” ìˆ˜í–‰ (ì—¬ëŸ¬ íŒŒì¼ ë³‘í•©)"""
    print("ğŸš€ ì „ì²˜ë¦¬ ì›Œì»¤ ìŠ¤ë ˆë“œ ì‹œì‘")
    
    # ì „ì²˜ë¦¬ ë””ë ‰í† ë¦¬ ìƒì„±
    if not os.path.exists(PROCESSED_DIR):
        os.makedirs(PROCESSED_DIR)

    while True:
        try:
            task = preprocess_queue.get()
            thread_id = task['thread_id']
            original_paths = task.get('original_paths', [])  # ë¦¬ìŠ¤íŠ¸ë¡œ ë°›ìŒ
            
            # ë‹¨ì¼ íŒŒì¼ì¸ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ (í•˜ìœ„ í˜¸í™˜ì„±)
            if not isinstance(original_paths, list):
                original_paths = [original_paths]
            
            if not original_paths:
                preprocess_queue.task_done()
                continue
            
            # ì „ì²´ íŒŒì¼ í¬ê¸° ê³„ì‚°
            total_size_mb = sum(os.path.getsize(p) / (1024 * 1024) for p in original_paths)
            print(f"ğŸ”§ ì „ì²˜ë¦¬ ì‹œì‘: {len(original_paths)}ê°œ íŒŒì¼, ì´ {total_size_mb:.2f} MB")
            
            try:
                # ì—¬ëŸ¬ PDFë¥¼ í•˜ë‚˜ë¡œ ë³‘í•© + ì „ì²˜ë¦¬
                merged_processed_path = merge_and_preprocess_pdfs(original_paths, PROCESSED_DIR, thread_id)
                
                if merged_processed_path:
                    # âœ¨ DB ì—…ë°ì´íŠ¸: ë³‘í•©ëœ íŒŒì¼ í•˜ë‚˜ì˜ ê²½ë¡œë¡œ êµì²´
                    conn = get_database_connection()
                    if conn:
                        try:
                            cursor = conn.cursor()
                            
                            # ì „ì²˜ë¦¬ëœ íŒŒì¼ í¬ê¸°
                            processed_size_mb = os.path.getsize(merged_processed_path) / (1024 * 1024)
                            
                            # DB ì—…ë°ì´íŠ¸: ë³‘í•©ëœ íŒŒì¼ ê²½ë¡œë§Œ ì €ì¥
                            sql = """UPDATE emails 
                                     SET attached_file_path = %s,
                                         file_rendered = 1
                                     WHERE thread_id = %s"""
                            cursor.execute(sql, (merged_processed_path, thread_id))
                            conn.commit()
                            
                            print(f"  âœ… ë³‘í•© ë° ì „ì²˜ë¦¬ ì™„ë£Œ:")
                            print(f"     ì›ë³¸: {len(original_paths)}ê°œ íŒŒì¼, {total_size_mb:.2f} MB")
                            print(f"     ì „ì²˜ë¦¬: 1ê°œ íŒŒì¼, {processed_size_mb:.2f} MB")
                            print(f"     ì €ì¥ ê²½ë¡œ: {merged_processed_path}")
                            
                        except Error as e:
                            print(f"  âš ï¸ DB ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
                            conn.rollback()
                        finally:
                            if conn.is_connected():
                                conn.close()
                else:
                    print(f"  âš ï¸ ì „ì²˜ë¦¬ ì‹¤íŒ¨: (ì›ë³¸ íŒŒì¼ ì‚¬ìš©)")
                
            except Exception as e:
                print(f"  âŒ ì „ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
                import traceback
                traceback.print_exc()
            finally:
                preprocess_queue.task_done()
                
        except Exception as e:
            print(f"âŒ ì „ì²˜ë¦¬ ì›Œì»¤ ì˜¤ë¥˜: {e}")
            time.sleep(5)


def merge_and_preprocess_pdfs(pdf_paths: list, processed_dir: str, thread_id: str) -> str | None:
    """ì—¬ëŸ¬ PDF íŒŒì¼ì„ í•˜ë‚˜ë¡œ ë³‘í•©í•˜ê³  ìµœì í™” (ë²¡í„° ìœ ì§€)
    
    Args:
        pdf_paths: ë³‘í•©í•  PDF íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        processed_dir: ì²˜ë¦¬ëœ íŒŒì¼ì„ ì €ì¥í•  ë””ë ‰í† ë¦¬
        thread_id: ë©”ì¼ ìŠ¤ë ˆë“œ ID (íŒŒì¼ëª… ìƒì„±ìš©)
    
    Returns:
        ë³‘í•© ë° ìµœì í™”ëœ PDF íŒŒì¼ ê²½ë¡œ (ì‹¤íŒ¨ ì‹œ None)
    """
    try:
        from pathlib import Path
        import pymupdf
        
        if not pdf_paths:
            return None
        
        # ë‹¨ì¼ íŒŒì¼ì¸ ê²½ìš° ê¸°ì¡´ í•¨ìˆ˜ ì‚¬ìš©
        if len(pdf_paths) == 1:
            return preprocess_pdf_for_rendering(pdf_paths[0], processed_dir)
        
        # ë³‘í•©ëœ íŒŒì¼ëª… ìƒì„±: thread_id ê¸°ë°˜
        merged_filename = f"{thread_id}_merged_processed.pdf"
        merged_path = os.path.join(processed_dir, merged_filename)
        
        # ì´ë¯¸ ì²˜ë¦¬ëœ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
        if os.path.exists(merged_path):
            # ëª¨ë“  ì›ë³¸ íŒŒì¼ë³´ë‹¤ ìµœì‹ ì¸ì§€ í™•ì¸
            merged_mtime = os.path.getmtime(merged_path)
            if all(merged_mtime >= os.path.getmtime(p) for p in pdf_paths if os.path.exists(p)):
                print(f"  âš¡ ì´ë¯¸ ë³‘í•© ì „ì²˜ë¦¬ë¨: {merged_filename}")
                return merged_path
        
        print(f"  ğŸ”§ {len(pdf_paths)}ê°œ PDF ë³‘í•© ë° ìµœì í™” ì¤‘...")
        
        # ë³‘í•© ë° A4 ìµœì í™”
        merged_doc = pymupdf.open()
        
        for idx, pdf_path in enumerate(pdf_paths):
            print(f"    - [{idx+1}/{len(pdf_paths)}] {os.path.basename(pdf_path)}")
            
            try:
                with pymupdf.open(pdf_path) as source_doc:
                    # ê° í˜ì´ì§€ë¥¼ A4ë¡œ ë³€í™˜í•˜ì—¬ ë³‘í•©
                    for page_num in range(len(source_doc)):
                        page = source_doc[page_num]
                        bounds = page.bound()
                        is_landscape = bounds.width > bounds.height
                        
                        if is_landscape:
                            a4_rect = pymupdf.paper_rect("a4-l")
                        else:
                            a4_rect = pymupdf.paper_rect("a4")
                        
                        # ìƒˆ A4 í˜ì´ì§€ ìƒì„±
                        new_page = merged_doc.new_page(width=a4_rect.width, height=a4_rect.height)
                        
                        # ë²¡í„° ê¸°ë°˜ìœ¼ë¡œ í˜ì´ì§€ ë³µì‚¬
                        new_page.show_pdf_page(new_page.rect, source_doc, page_num)
            
            except Exception as e:
                print(f"    âš ï¸ íŒŒì¼ ë³‘í•© ì‹¤íŒ¨: {os.path.basename(pdf_path)} - {e}")
                continue
        
        # ë³‘í•©ëœ PDF ì €ì¥ (ìµœì í™”)
        merged_doc.save(
            merged_path,
            garbage=4,
            deflate=True,
            clean=True,
            pretty=False,
            linear=False,
        )
        merged_doc.close()
        
        print(f"  âœ… ë³‘í•© ì™„ë£Œ: {merged_filename}")
        return merged_path
        
    except Exception as e:
        print(f"  âš ï¸ ë³‘í•© ë° ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return None


def preprocess_pdf_for_rendering(original_path: str, processed_dir: str) -> str | None:
    """PDFë¥¼ ë Œë”ë§ì— ìµœì í™”ëœ í˜•íƒœë¡œ ì „ì²˜ë¦¬ (3MB ì´ˆê³¼ íŒŒì¼ìš©)
    
    ì „ëµ: ë²¡í„° ê¸°ë°˜ í˜ì´ì§€ëŠ” ê·¸ëŒ€ë¡œ ë³µì‚¬, ì´ë¯¸ì§€ê°€ ë§ì€ í˜ì´ì§€ë§Œ ìµœì í™”
    """
    try:
        from pathlib import Path
        import pymupdf
        
        # íŒŒì¼ëª… ìƒì„±
        base_name = Path(original_path).stem
        processed_filename = f"{base_name}_processed.pdf"
        processed_path = os.path.join(processed_dir, processed_filename)
        
        # ì´ë¯¸ ì²˜ë¦¬ëœ íŒŒì¼ì´ ìˆê³  ìµœì‹ ì´ë©´ ìŠ¤í‚µ
        if os.path.exists(processed_path):
            if os.path.getmtime(processed_path) >= os.path.getmtime(original_path):
                print(f"  âš¡ ì´ë¯¸ ì „ì²˜ë¦¬ë¨: {processed_filename}")
                return processed_path
        
        print(f"  ğŸ”§ PDF ìµœì í™” ì¤‘: {base_name}")
        
        # ë‹¨ìˆœ ìµœì í™”: garbage collection + deflate + clean
        # ë²¡í„° ë°ì´í„°ëŠ” ìœ ì§€í•˜ë©´ì„œ ë¶ˆí•„ìš”í•œ ê°ì²´ë§Œ ì œê±°
        with pymupdf.open(original_path) as source_doc:
            # A4 ê·œê²©ìœ¼ë¡œ ë³€í™˜í•˜ë˜, ë²¡í„° ë°ì´í„°ë¥¼ ìœ ì§€í•˜ëŠ” ë°©ì‹
            new_doc = pymupdf.open()
            
            for page_num in range(len(source_doc)):
                page = source_doc[page_num]
                bounds = page.bound()
                is_landscape = bounds.width > bounds.height
                
                if is_landscape:
                    a4_rect = pymupdf.paper_rect("a4-l")
                else:
                    a4_rect = pymupdf.paper_rect("a4")
                
                # ìƒˆ A4 í˜ì´ì§€ ìƒì„±
                new_page = new_doc.new_page(width=a4_rect.width, height=a4_rect.height)
                
                # show_pdf_page: ë²¡í„° ê¸°ë°˜ìœ¼ë¡œ í˜ì´ì§€ë¥¼ ë³µì‚¬ (ì´ë¯¸ì§€ë¡œ ë³€í™˜í•˜ì§€ ì•ŠìŒ)
                new_page.show_pdf_page(new_page.rect, source_doc, page_num)
            
            # ê°•ë ¥í•œ ìµœì í™” ì˜µì…˜ìœ¼ë¡œ ì €ì¥
            new_doc.save(
                processed_path,
                garbage=4,          # ìµœëŒ€ garbage collection
                deflate=True,       # ì••ì¶• í™œì„±í™”
                clean=True,         # ë¶ˆí•„ìš”í•œ ê°ì²´ ì œê±°
                pretty=False,       # ê°€ë…ì„± ì œê±° (í¬ê¸° ê°ì†Œ)
                linear=False,       # ì„ í˜•í™” ë¹„í™œì„±í™” (ì›¹ ìµœì í™” ë¶ˆí•„ìš”)
            )
            new_doc.close()
        
        return processed_path
        
    except Exception as e:
        print(f"  âš ï¸ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return None


if __name__ == "__main__":
    print("="*50)
    print(" ë©”ì¼ ìˆ˜ì§‘ ë° ì²¨ë¶€íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì„œë¹„ìŠ¤ ì‹œì‘")
    print(f" ì „ì²˜ë¦¬ ì„ê³„ê°’: {PREPROCESS_THRESHOLD_MB} MB ì´ˆê³¼")
    print("="*50)

    # 1. ë©”ì¼ ìˆ˜ì§‘ ìŠ¤ë ˆë“œ (20ì´ˆ ì£¼ê¸°)
    mail_collector = threading.Thread(target=db_mail_thread, daemon=True)
    mail_collector.start()

    # 2. ë‹¤ìš´ë¡œë“œ ì›Œì»¤ ìŠ¤ë ˆë“œ
    attachment_downloader = threading.Thread(target=download_worker_thread, daemon=True)
    attachment_downloader.start()

    # 3. ì „ì²˜ë¦¬ ì›Œì»¤ ìŠ¤ë ˆë“œ (ìƒˆë¡œ ì¶”ê°€!)
    pdf_preprocessor = threading.Thread(target=preprocess_worker_thread, daemon=True)
    pdf_preprocessor.start()

    # ë©”ì¸ ìŠ¤ë ˆë“œëŠ” ë°ëª¬ ìŠ¤ë ˆë“œê°€ ì¢…ë£Œë˜ì§€ ì•Šë„ë¡ ìœ ì§€
    try:
        # ìŠ¤ë ˆë“œê°€ ì‚´ì•„ìˆëŠ”ì§€ ì£¼ê¸°ì ìœ¼ë¡œ í™•ì¸
        while (mail_collector.is_alive() and 
               attachment_downloader.is_alive() and 
               pdf_preprocessor.is_alive()):
            time.sleep(1)
    except KeyboardInterrupt:
        print("\nğŸš« ì„œë¹„ìŠ¤ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
