import pathlib
import os
import re
import json
import time
import io
import sys
from google import genai
from google.genai import types # types.Part ì‚¬ìš©ì„ ìœ„í•´ ì¶”ê°€
import PyPDF2
import pandas as pd
from concurrent.futures import ThreadPoolExecutor, as_completed

# config.pyì—ì„œ API_KEY ì„í¬íŠ¸ (config.py íŒŒì¼ì´ ê°™ì€ ë””ë ‰í† ë¦¬ì— ìˆë‹¤ê³  ê°€ì •)
from config import API_KEY 

client = genai.Client(api_key=API_KEY)

# main.pyì—ì„œ ê°€ì ¸ì˜¨ parse_response í•¨ìˆ˜ (ê³„ì•½ì„œ ì •ë³´ìš©)
def parse_response_contract(text):
    """AI ì‘ë‹µì—ì„œ JSONì„ íŒŒì‹±í•˜ì—¬ ë‚ ì§œ, ì°¨ëŸ‰êµ¬ì„±, ê³ ê°ëª…, RNë²ˆí˜¸, íœ´ëŒ€í°ë²ˆí˜¸, ì´ë©”ì¼, í˜ì´ì§€ë²ˆí˜¸ ì •ë³´ ì¶”ì¶œ"""
    if text is None:
        return None, None, None, None, None, None, None
    
    try:
        json_match = re.search(r'\{.*\}', text, re.DOTALL)
        if json_match:
            json_str = json_match.group()
            data = json.loads(json_str)
            return (data.get('order_date'), data.get('vehicle_config'), 
                   data.get('customer_name'), data.get('rn'),
                   data.get('phone_number'), data.get('email'), data.get('page_number'))
    except:
        pass
    
    date = extract_date(text)
    return date, None, None, None, None, None, None

def extract_date(text):
    """í…ìŠ¤íŠ¸ì—ì„œ ë‚ ì§œë¥¼ YYYY-MM-DD í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œ"""
    if text is None:
        return None
    
    patterns = [
        r'(\d{4})ë…„\s*(\d{1,2})ì›”\s*(\d{1,2})ì¼',
        r'(\d{4})/(\d{1,2})/(\d{1,2})',
        r'(\d{4})-(\d{1,2})-(\d{1,2})',
    ]
    
    for pattern in patterns:
        match = re.search(pattern, text)
        if match:
            year, month, day = match.groups()
            return f"{year}-{month.zfill(2)}-{day.zfill(2)}"
    
    return None

# ì´ˆë³¸.pyì—ì„œ ê°€ì ¸ì˜¨ parse_response í•¨ìˆ˜ (ì£¼ë¯¼ë“±ë¡ì´ˆë³¸ ì •ë³´ìš©)
def parse_response_resident_cert(text):
    """AI ì‘ë‹µì—ì„œ JSONì„ íŒŒì‹±í•˜ì—¬ ì£¼ë¯¼ë“±ë¡ì´ˆë³¸ ì •ë³´ ì¶”ì¶œ"""
    if text is None:
        return None
    
    try:
        json_match = re.search(r'\{.*\}', text, re.DOTALL)
        if json_match:
            json_str = json_match.group()
            data = json.loads(json_str)
            
            if data.get('name'):
                data['name'] = data['name'].replace(' ', '').replace('\n', '').replace('\r', '').replace('\t', '')
            
            if data.get('address_1'):
                address = data['address_1']
                if 'ê°•ì›ë„' in address:
                    address = address.replace('ê°•ì›ë„', 'ê°•ì›íŠ¹ë³„ìì¹˜ë„')
                if 'ì „ë¼ë¶ë„' in address:
                    address = address.replace('ì „ë¼ë¶ë„', 'ì „ë¶íŠ¹ë³„ìì¹˜ë„')
                data['address_1'] = address
            
            if data.get('address_2'):
                address = data['address_2']
                if 'ê°•ì›ë„' in address:
                    address = address.replace('ê°•ì›ë„', 'ê°•ì›íŠ¹ë³„ìì¹˜ë„')
                if 'ì „ë¼ë¶ë„' in address:
                    address = address.replace('ì „ë¼ë¶ë„', 'ì „ë¶íŠ¹ë³„ìì¹˜ë„')
                data['address_2'] = address
            
            if data.get('issue_date'):
                issue_date = data['issue_date']
                date_match = re.search(r'(\d{4})ë…„\s*(\d{1,2})ì›”\s*(\d{1,2})ì¼', issue_date)
                if date_match:
                    year = date_match.group(1)
                    month = date_match.group(2).zfill(2)
                    day = date_match.group(3).zfill(2)
                    data['issue_date'] = f"{year}-{month}-{day}"
            
            return data
    except:
        pass
    
    return None

def parse_response_dajanyeo(text):
    """AI ì‘ë‹µì—ì„œ JSONì„ íŒŒì‹±í•˜ì—¬ ê°€ì¡±ê´€ê³„ì¦ëª…ì„œ ì •ë³´ ì¶”ì¶œ"""
    if text is None:
        return None
    
    try:
        # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ (```json``` ë¸”ë¡ì´ ìˆì„ ìˆ˜ ìˆìŒ)
        json_match = re.search(r'\{.*\}', text, re.DOTALL)
        if json_match:
            json_str = json_match.group()
            data = json.loads(json_str)
            
            # child_count í•„ë“œ ê²€ì¦ (ìˆ«ìì¸ì§€ í™•ì¸)
            if 'child_count' in data and data['child_count'] is not None:
                try:
                    data['child_count'] = int(data['child_count'])
                except (ValueError, TypeError):
                    data['child_count'] = None
            
            # child_birth_date í•„ë“œ ê²€ì¦ (ë¦¬ìŠ¤íŠ¸ì¸ì§€ í™•ì¸)
            if 'child_birth_date' in data and data['child_birth_date'] is not None:
                if not isinstance(data['child_birth_date'], list):
                    data['child_birth_date'] = None
            
            # page_number í•„ë“œ ê²€ì¦ (ìˆ«ìì¸ì§€ í™•ì¸)
            if 'page_number' in data and data['page_number'] is not None:
                try:
                    data['page_number'] = int(data['page_number'])
                except (ValueError, TypeError):
                    data['page_number'] = None
            
            return data
    except Exception as e:
        print(f"âš ï¸  JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
        pass
    
    return None

def parse_response_cheongnyeon(text):
    """AI ì‘ë‹µì—ì„œ JSONì„ íŒŒì‹±í•˜ì—¬ ì²­ë…„ìƒì•  ì •ë³´ ì¶”ì¶œ"""
    if text is None:
        return None
    
    try:
        # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ (```json``` ë¸”ë¡ì´ ìˆì„ ìˆ˜ ìˆìŒ)
        json_match = re.search(r'\{.*\}', text, re.DOTALL)
        if json_match:
            json_str = json_match.group()
            data = json.loads(json_str)
            
            # local_name í•„ë“œ ê²€ì¦ (ë¦¬ìŠ¤íŠ¸ì¸ì§€ í™•ì¸)
            if 'local_name' in data and data['local_name'] is not None:
                if not isinstance(data['local_name'], list):
                    data['local_name'] = None
            
            # range_date í•„ë“œ ê²€ì¦ (ë¦¬ìŠ¤íŠ¸ì¸ì§€ í™•ì¸)
            if 'range_date' in data and data['range_date'] is not None:
                if not isinstance(data['range_date'], list):
                    data['range_date'] = None
            
            return data
    except Exception as e:
        print(f"âš ï¸  JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
        pass
    
    return None

def is_valid_pdf(filepath):
    """PDF íŒŒì¼ì´ ìœ íš¨í•œì§€ ê²€ì‚¬ (í˜ì´ì§€ê°€ ìˆëŠ”ì§€ í™•ì¸)"""
    try:
        with open(filepath, 'rb') as file:
            pdf_reader = PyPDF2.PdfReader(file)
            return len(pdf_reader.pages) > 0
    except Exception:
        return False

def process_single_rn(rn, filepath, category, supabase_manager):
    """
    í•˜ë‚˜ì˜ RNì— ëŒ€í•´ ì¹´í…Œê³ ë¦¬ì— ë”°ë¼ í•„ìš”í•œ ëª¨ë“  í”„ë¡¬í”„íŠ¸ë¥¼ ë³‘ë ¬ë¡œ ì²˜ë¦¬í•˜ê³  Supabaseì— ì €ì¥
    """
    start_time = time.time()
    results = {}
    
    print(f"\n--- [{rn}] íŒŒì¼ ì²˜ë¦¬ ì‹œì‘ (ì¹´í…Œê³ ë¦¬: {category}) ---")
    
    # PDF ë°”ì´íŠ¸ ë°ì´í„° ë¯¸ë¦¬ ì½ê¸°
    pdf_bytes = pathlib.Path(filepath).read_bytes()
    
    def call_api(prompt_text, result_key, parse_function):
        """API í˜¸ì¶œ ë° ê²°ê³¼ íŒŒì‹±ì„ ìœ„í•œ ê³µí†µ í•¨ìˆ˜"""
        try:
            print(f"  ğŸ”„ [{rn}] {result_key} í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬ ì‹œì‘...")
            response = client.models.generate_content(
                model="gemini-2.5-flash",
                contents=[
                    types.Part.from_bytes(data=pdf_bytes, mime_type='application/pdf'),
                    prompt_text
                ]
            )
            # ê³„ì•½ì„œì˜ ê²½ìš° parse_response_contractê°€ íŠœí”Œì„ ë°˜í™˜í•˜ë¯€ë¡œ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
            if parse_function == parse_response_contract:
                order_date, vehicle_config, customer_name, extracted_rn, phone_number, email, page_number = parse_function(response.text)
                data = {
                    'order_date': order_date,
                    'vehicle_config': vehicle_config,
                    'customer_name': customer_name,
                    'rn': extracted_rn,
                    'phone_number': phone_number,
                    'email': email,
                    'page_number': page_number
                }
            else:
                data = parse_function(response.text)
                
            print(f"  âœ… [{rn}] {result_key} í”„ë¡¬í”„íŠ¸ ì™„ë£Œ")
            return (result_key, data)
        except Exception as e:
            print(f"  âŒ [{rn}] {result_key} í”„ë¡¬í”„íŠ¸ ì‹¤íŒ¨: {e}")
            return (result_key, None)

    # ì‹¤í–‰í•  API ì‘ì—… ëª©ë¡
    tasks = [
        (prompt_contract, 'contract_data', parse_response_contract),
        (prompt_resident_cert, 'resident_cert_data', parse_response_resident_cert)
    ]

    if 'ë‹¤ìë…€' in category:
        tasks.append((prompt_dajanyeo, 'dajanyeo_data', parse_response_dajanyeo))
    if 'ì²­ë…„ìƒì• ' in category:
        tasks.append((prompt_cheongnyeon, 'cheongnyeon_data', parse_response_cheongnyeon))

    # API ë³‘ë ¬ í˜¸ì¶œ
    with ThreadPoolExecutor(max_workers=len(tasks)) as executor:
        futures = [executor.submit(call_api, *task) for task in tasks]
        
        for future in as_completed(futures):
            result_key, data = future.result()
            results[result_key] = data
            
    elapsed_time = time.time() - start_time
    print(f"--- [{rn}] íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ ({round(elapsed_time, 2)}s) ---")

    # Supabaseì— ê²°ê³¼ ì €ì¥
    if supabase_manager:
        for result_key, data in results.items():
            if data:
                # ì¹´í…Œê³ ë¦¬ëª…ì„ test_categoryì— ë§ê²Œ ë³€í™˜
                category_map = {
                    'contract_data': 'êµ¬ë§¤ê³„ì•½ì„œ',
                    'resident_cert_data': 'ì´ˆë³¸',
                    'dajanyeo_data': 'ë‹¤ìë…€',
                    'cheongnyeon_data': 'ì²­ë…„ìƒì• '
                }
                test_category = category_map.get(result_key, 'ê¸°íƒ€')

                try:
                    success = supabase_manager.insert_test_result(
                        rn=rn,
                        test_category=test_category,
                        test_success=True,
                        test_model='gemini-2.5-flash',
                        memo=f'ë³‘ë ¬ì²˜ë¦¬ ì™„ë£Œ ({round(elapsed_time, 2)}s)',
                        process_seconds=elapsed_time,
                        result_data=data
                    )
                    if success:
                        print(f"  âœ… [{rn}] {test_category} ë°ì´í„° Supabase ì €ì¥ ì™„ë£Œ")
                    else:
                        print(f"  âŒ [{rn}] {test_category} ë°ì´í„° Supabase ì €ì¥ ì‹¤íŒ¨")
                except Exception as e:
                    print(f"  âŒ [{rn}] {test_category} Supabase ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")

    return results

def process_single_rn_with_timing(rn, filepath, category, supabase_manager):
    """
    í•˜ë‚˜ì˜ RN ì²˜ë¦¬ + ì‹œê°„ ì¸¡ì •ì„ í¬í•¨í•œ ë˜í¼ í•¨ìˆ˜
    """
    start_time = time.time()
    result = process_single_rn(rn, filepath, category, supabase_manager)
    end_time = time.time()
    individual_time = end_time - start_time
    return result, individual_time

def process_multiple_rns(rn_info_list, download_folder, supabase_manager):
    """
    ì—¬ëŸ¬ RNì— ëŒ€í•´ ë³‘ë ¬ ì²˜ë¦¬ (RNë³„ë¡œ ë‚´ë¶€ì—ì„œ í•„ìš”í•œ ë¬¸ì„œë“¤ ë³‘ë ¬ ì²˜ë¦¬)
    """
    total_start_time = time.time()
    print(f"\nğŸš€ {len(rn_info_list)}ê°œ RN ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘...")
    
    # ê° RNì— ëŒ€í•œ íŒŒì¼ ê²½ë¡œ ë° ì¹´í…Œê³ ë¦¬ ì •ë³´ ì°¾ê¸°
    rn_process_info = []
    for rn_info in rn_info_list:
        rn = rn_info['rn']
        category = rn_info['category']
        filepath = download_folder / rn_info['filename']
        
        if filepath.exists() and is_valid_pdf(filepath):
            rn_process_info.append({'rn': rn, 'filepath': filepath, 'category': category})
        else:
            print(f"âš ï¸  {rn}: PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ì†ìƒë¨ ({filepath})")
    
    if not rn_process_info:
        print("âŒ ì²˜ë¦¬í•  ìœ íš¨í•œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return {}, 0, 0
    
    print(f"ğŸ“„ {len(rn_process_info)}ê°œ ìœ íš¨í•œ íŒŒì¼ ë°œê²¬")
    
    # ì—¬ëŸ¬ RNì„ ë³‘ë ¬ë¡œ ì²˜ë¦¬
    all_results = {}
    individual_times = {}  # ê° RNë³„ ì²˜ë¦¬ ì‹œê°„ ì €ì¥
    
    with ThreadPoolExecutor(max_workers=3) as executor:  # ìµœëŒ€ 3ê°œ RN ë™ì‹œ ì²˜ë¦¬
        futures = []
        
        for info in rn_process_info:
            future = executor.submit(
                process_single_rn_with_timing, 
                info['rn'], 
                info['filepath'], 
                info['category'],
                supabase_manager
            )
            futures.append((info['rn'], future))
        
        # ê²°ê³¼ ìˆ˜ì§‘
        for rn, future in futures:
            try:
                result, individual_time = future.result()
                all_results[rn] = result
                individual_times[rn] = individual_time
            except Exception as e:
                print(f"âŒ [{rn}] ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                all_results[rn] = {}
                individual_times[rn] = 0
    
    total_end_time = time.time()
    total_time = total_end_time - total_start_time
    
    return all_results, total_time, individual_times

def remove_processed_rns_from_excel(excel_path, processed_rns):
    """
    ì—‘ì…€ íŒŒì¼ì—ì„œ ì²˜ë¦¬ ì™„ë£Œëœ RNë“¤ì„ ì œê±°í•©ë‹ˆë‹¤.

    Args:
        excel_path (str): ì—‘ì…€ íŒŒì¼ ê²½ë¡œ
        processed_rns (list): ì²˜ë¦¬ ì™„ë£Œëœ RN ë¦¬ìŠ¤íŠ¸
    """
    if not processed_rns:
        print("\nâ„¹ï¸  ì—‘ì…€ì—ì„œ ì œê±°í•  RNì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    try:
        print(f"\nğŸ”„ '{excel_path}'ì—ì„œ ì²˜ë¦¬ ì™„ë£Œëœ {len(processed_rns)}ê°œ RN ì œê±° ì¤‘...")
        df = pd.read_excel(excel_path)
        
        # 'ì œì¡°ìˆ˜ì…ì‚¬\nê´€ë¦¬ë²ˆí˜¸' ì»¬ëŸ¼ì´ ì‹¤ì œ íŒŒì¼ì— ìˆëŠ” ì»¬ëŸ¼ëª…ê³¼ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.
        # mail_download.pyë¥¼ ì°¸ê³ í•˜ì—¬ ì»¬ëŸ¼ëª…ì„ ì •í™•íˆ ê¸°ì¬í•©ë‹ˆë‹¤.
        rn_column_name = 'ì œì¡°ìˆ˜ì…ì‚¬\nê´€ë¦¬ë²ˆí˜¸'
        
        initial_row_count = len(df)
        df = df[~df[rn_column_name].isin(processed_rns)]
        final_row_count = len(df)
        
        # ì¸ë±ìŠ¤ë¥¼ ì¬ì„¤ì •í•˜ì§€ ì•Šê³  ì €ì¥í•˜ì—¬ ì›ë³¸ í˜•ì‹ ìœ ì§€ ì‹œë„
        df.to_excel(excel_path, index=False)
        
        print(f"âœ… ì—‘ì…€ íŒŒì¼ ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
        print(f"   - ì´ì „ í–‰ ê°œìˆ˜: {initial_row_count}")
        print(f"   - ì œê±°ëœ í–‰ ê°œìˆ˜: {initial_row_count - final_row_count}")
        print(f"   - í˜„ì¬ í–‰ ê°œìˆ˜: {final_row_count}")

    except FileNotFoundError:
        print(f"âŒ ì—‘ì…€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {excel_path}")
    except KeyError:
        print(f"âŒ ì—‘ì…€ íŒŒì¼ì—ì„œ '{rn_column_name}' ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ ì—‘ì…€ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# --- í”„ë¡¬í”„íŠ¸ ì •ì˜ ---
prompt_contract = """ìë™ì°¨ êµ¬ë§¤ ê³„ì•½ ì„œë¥˜ì—ì„œ ë‹¤ìŒ ì •ë³´ë¥¼ ì°¾ì•„ì„œ JSON í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:

1. 'ì˜¨ë¼ì¸ ì£¼ë¬¸ ì™„ë£Œì¼' ë‚ ì§œ (YYYY-MM-DD í˜•ì‹)
2. 'ì°¨ëŸ‰êµ¬ì„±' ë˜ëŠ” 'ì°¨ëŸ‰ êµ¬ì„±ë‚´ì—­' ì„¹ì…˜ì—ì„œ ì²« ë²ˆì§¸ í–‰ì˜ êµ¬ì„±ë‚´ì—­
3. 'ê³ ê°ì •ë³´' ì„¹ì…˜ì—ì„œ 'ê³ ê° ì´ë¦„' - ì˜ë¬¸ í˜¹ì€ í•œê¸€ë¡œ ì íŒ ì´ë¦„
4. 'ì˜ˆì•½ ë²ˆí˜¸'ì— ì íŒ 'RN123456789' í˜•ì‹ì˜ ë²ˆí˜¸
5. 'ê³ ê°ì •ë³´' ì„¹ì…˜ì—ì„œ íœ´ëŒ€í° ë²ˆí˜¸ì™€ ì´ë©”ì¼ ì£¼ì†Œ
6. ë§ˆì§€ë§‰ìœ¼ë¡œ ì´ ì •ë³´ê°€ ë‹´ê¸´ í˜ì´ì§€ ë²ˆí˜¸ë¥¼ page_number í•„ë“œì— ì €ì¥

ë‹µë³€ í˜•ì‹:
{
  "order_date": "2025-10-06",
  "vehicle_config": "Model Y í›„ë¥œêµ¬ë™",
  "customer_name": "John Doe",
  "rn": "RN123456789",
  "phone_number": "010-1234-5678",
  "email": "john.doe@naver.com",
  "page_number": 3
}

ì˜¨ë¼ì¸ ì£¼ë¬¸ ì™„ë£Œì¼ ì˜ˆì‹œ:
- 2025/10/06 â†’ 2025-10-06

íŒë‹¨í•´ì•¼í•˜ëŠ” ì„œë¥˜ëŠ” "ìë™ì°¨ êµ¬ë§¤ ê³„ì•½"ê³¼ "ì°¨ëŸ‰ êµ¬ì„±"ì´ë¼ëŠ” ê¸€ìê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

ì°¨ëŸ‰êµ¬ì„±ì€ ì •í™•íˆ ì²« ë²ˆì§¸ í–‰ì— ì íŒ ë‚´ìš©ë§Œ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

ì´ë©”ì¼ ì£¼ì†Œ ë° íœ´ëŒ€í° ë²ˆí˜¸ ì¶”ì¶œ ì‹œ ì£¼ì˜ì‚¬í•­:
- ëŒ€ë¶€ë¶„ì˜ ì´ë©”ì¼ì´ ë‹¤ìŒ ë„ë©”ì¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤: naver.com, gmail.com, hanmail.net, nate.com, daum.net
- ì´ë©”ì¼ ì£¼ì†ŒëŠ” ì •í™•íˆ @ ê¸°í˜¸ ì•ë’¤ë¡œ êµ¬ì„±ë˜ì–´ì•¼ í•©ë‹ˆë‹¤
- ì´ë©”ì¼ í˜•ì‹ì´ ëª…í™•í•˜ì§€ ì•Šìœ¼ë©´ nullë¡œ ì„¤ì •í•´ì£¼ì„¸ìš”
- íœ´ëŒ€í° ë²ˆí˜¸ëŠ” 010-XXXX-XXXX í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œí•´ì£¼ì„¸ìš”

"""

prompt_resident_cert = """ì£¼ë¯¼ë“±ë¡ì´ˆë³¸ì—ì„œ ë‹¤ìŒ ì •ë³´ë¥¼ ì°¾ì•„ì„œ JSON í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:

1. ëª¨ë“  í˜ì´ì§€ì—ì„œ 'ë§ˆì§€ë§‰ ë²ˆí˜¸'ì— í•´ë‹¹í•˜ëŠ” ['ì£¼ì†Œ', 'ë°œìƒì¼'] ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”. ë°œìƒì¼ì€ at_date í•„ë“œì— ì €ì¥í•´ì£¼ì„¸ìš”.
2. 'ì£¼ì†Œ'ëŠ” ëŒ€ë¶€ë¶„ 2ì¤„ë¡œ ë˜ì–´ ìˆëŠ”ë° 2ì¤„ì„ ê°ê° [address_1, address_2] í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œí•´ì£¼ì„¸ìš”. ',' ì‰¼í‘œì™€ '.' ë¬¸ìëŠ” ì œê±°í•´ì£¼ì„¸ìš”.
3. 'ë°œìƒì¼'ì€ YYYY-MM-DD í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œí•´ì£¼ì„¸ìš”.
4. 'ì„±ëª…', 'ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸'ë¥¼ ì¶”ì¶œí•œ í›„ ì• 6ìë¦¬ì˜ ìˆ«ìë¥¼ birth_date í•„ë“œì— ì €ì¥í•´ì£¼ì„¸ìš”. 950516-1234567 -> 1995-05-16
5. ì•„ë¬´ í˜ì´ì§€ ìƒë‹¨ì— '2025ë…„' ì´ë¼ëŠ” ë¬¸ìì—´ì„ ì°¾ì•„ì„œ ì¼ì ì „ì²´ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”. issue_date í•„ë“œì— ì €ì¥í•´ì£¼ì„¸ìš”.
6. ì£¼ë¯¼ë“±ë¡ì´ˆë³¸ ë°ì´í„°ê°€ í¬í•¨ëœ ëª¨ë“  í˜ì´ì§€ ë²ˆí˜¸ë¥¼ page_number í•„ë“œì— ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ì €ì¥í•´ì£¼ì„¸ìš”.
7. ì´ˆë³¸ì´ ì—†ë‹¤ê³  íŒë‹¨ë˜ë©´ ëª¨ë“  ê°’ì„ Noneìœ¼ë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”.


ë‹µë³€ í˜•ì‹:
{
  address_1: "ì„œìš¸íŠ¹ë³„ì‹œ ê°•ë‚¨êµ¬ ì—­ì‚¼ë™ 123-45",
  address_2: "ìì´ì•„íŒŒíŠ¸ 101ë™ 101í˜¸"
  at_date: "2025-04-16",
  birth_date: "1999-10-06",
  name: "í™ê¸¸ë™",
  issue_date: "2025-04-16",
  page_number: [3, 4, 5]
}

ì£¼ì†Œì™€ ë°œìƒì¼ì€ ëª¨ë“  í˜ì´ì§€ ì¤‘ì—ì„œ 'ë²ˆí˜¸'ê°€ ê°€ì¥ ë†’ì€ rowì— ëŒ€í•´ì„œ ì¶”ì¶œí•´ì£¼ì„¸ìš”. ë§ˆì§€ë§‰ í˜ì´ì§€ê°€ ì•„ë‹Œ ê°€ì¥ í° ë²ˆí˜¸ê°€ í¬í•¨ëœ í˜ì´ì§€ì—ì„œ ì¶”ì¶œí•´ì£¼ì„¸ìš”.
ì´ˆë³¸ì´ 1í˜ì´ì§€ë§Œ ìˆìœ¼ë©´ [3], ì—¬ëŸ¬ í˜ì´ì§€ì— ê±¸ì³ìˆìœ¼ë©´ [3, 4, 5, 6]ì²˜ëŸ¼ ëª¨ë“  í˜ì´ì§€ ë²ˆí˜¸ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”.

issue_date ì¶”ì¶œ ì‹œ ì£¼ì˜ì‚¬í•­:
- í•­ìƒ '0000ë…„ 0ì›” 00ì¼' ì²˜ëŸ¼ ì“°ì—¬ì ¸ ìˆìŠµë‹ˆë‹¤.
- '0000-00-00' ìœ¼ë¡œ ì“°ì—¬ì ¸ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.
- í•­ìƒ '2025ë…„' ì´ë¼ëŠ” ë¬¸ìì—´ì„ ì°¾ì•„ì„œ ì¼ì ì „ì²´ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”.
- ëŒ€ë¶€ë¶„ í˜ì´ì§€ ìƒë‹¨ì— ì¡´ì¬í•©ë‹ˆë‹¤.
"""

prompt_dajanyeo = """[ê°€ì¡±ê´€ê³„ì¦ëª…ì„œ]ì—ì„œ ë‹¤ìŒ ì •ë³´ë¥¼ ì°¾ì•„ì„œ JSON í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”. [ê°€ì¡±ê´€ê³„ì¦ëª…ì„œ] ì„œë¥˜ê°€ ë³´ì´ì§€ ì•Šë‹¤ë©´ ëª¨ë“  ë°˜í™˜ê°’ì„ nullë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”.:

í™•ì¸ ì‚¬í•­:
1. ëª¨ë“  ì„œë¥˜ ì¤‘ "ê°€ì¡±ê´€ê³„ì¦ëª…ì„œ"ë¼ëŠ” ê¸€ìê°€ ìƒë‹¨ì— í‘œì‹œëœ ì„œë¥˜ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.
2. ê°€ì¡±ê´€ê³„ì¦ëª…ì„œ ìƒ ['êµ¬ë¶„']ì´ 'ìë…€'ì¸ ê²ƒì´ 2ê°œ ì´ìƒì¸ì§€ í™•ì¸í•˜ì„¸ìš”.

ì¶”ì¶œ ì‚¬í•­:
1. ê°€ì¡±ê´€ê³„ì¦ëª…ì„œ ìƒ ['êµ¬ë¶„']ì´ 'ìë…€'ì˜ ê°œìˆ˜ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.
2. ê°€ì¡±ê´€ê³„ì¦ëª…ì„œ ìƒ ['êµ¬ë¶„']ì´ 'ìë…€'ì˜ ê° rowì¤‘ ['ì¶œìƒì—°ì›”ì¼']ì— ëŒ€í•œ ê°’ì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”. (ì¶œìƒì—°ì›”ì¼ì€ YYYY-MM-DD í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œí•˜ì„¸ìš”. ì˜ˆ: 1999ë…„ 01ì›” 01ì¼ â†’ "1999-01-01")
3. ê°€ì¡±ê´€ê³„ì¦ëª…ì„œê°€ ìœ„ì¹˜í•œ í˜ì´ì§€ ë²ˆí˜¸ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

ë‹µë³€ í˜•ì‹ (JSON í˜•ì‹ì„ ì •í™•íˆ ì§€ì¼œì„œ ë‹µë³€í•´ì£¼ì„¸ìš”):
{
  "child_count": 2,
  "child_birth_date": ["1999-01-01", "2001-05-15"],
  "page_number": 1
}

ì¤‘ìš”:
- ê°€ì¡±ê´€ê³„ì¦ëª…ì„œê°€ ì—†ë‹¤ë©´ {"child_count": null, "child_birth_date": null, "page_number": null}ì„ ë°˜í™˜í•´ì£¼ì„¸ìš”.
- child_countì™€ page_numberëŠ” ìˆ«ìë§Œ ë°˜í™˜í•´ì£¼ì„¸ìš”.
- child_birth_dateëŠ” ë°°ì—´ë¡œ ë°˜í™˜í•˜ê³ , ê° ë‚ ì§œëŠ” "YYYY-MM-DD" í˜•ì‹ì˜ ë¬¸ìì—´ë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”.
- JSON í‚¤ëŠ” ë°˜ë“œì‹œ í°ë”°ì˜´í‘œë¡œ ê°ì‹¸ì£¼ì„¸ìš”.
"""

prompt_cheongnyeon = """[ì§€ë°©ì„¸ ì„¸ëª©ë³„ ê³¼ì„¸ì¦ëª…ì„œ]ì—ì„œ ë‹¤ìŒ ì •ë³´ë¥¼ ì°¾ì•„ì„œ JSON í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.

í™•ì¸ ì‚¬í•­:
1. ê³¼ì„¸ì‚¬ì‹¤ì´ í•˜ë‚˜ë¼ë„ ìˆë‹¤ë©´ ëª¨ë“  ë°˜í™˜ê°’ì„ nullë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”.
2. [ì§€ë°©ì„¸ ì„¸ëª©ë³„ ê³¼ì„¸ì¦ëª…ì„œ] ì„œë¥˜ê°€ ì—†ë‹¤ë©´ ëª¨ë“  ë°˜í™˜ê°’ì„ nullë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”.

ì¶”ì¶œ ì‚¬í•­:
1. ëª¨ë“  [ì§€ë°©ì„¸ ì„¸ëª©ë³„ ê³¼ì„¸ì¦ëª…ì„œ]ë¥¼ ê²€í† í•´ì„œ 'ë‚´ìš©' ë¶€ë¶„ì— ìˆëŠ” 'ì§€ì—­ëª…' í˜¹ì€ 'ì „êµ­ ìì¹˜ë‹¨ì²´'ì— í•´ë‹¹í•˜ëŠ” ê°’ì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”.
2. ê³¼ì„¸ë…„ë„ì— í•´ë‹¹í•˜ëŠ” 'ë²”ìœ„ ì—°ë„' í˜•ì‹ì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

ì£¼ì˜ ì‚¬í•­:
- [ì§€ë°©ì„¸ ë‚©ì„¸ì¦ëª…(ì‹ ì²­)ì„œ] ì„œë¥˜ì™€ëŠ” ë‹¤ë¥¸ ì„œë¥˜ì…ë‹ˆë‹¤ ì´ ì  ì£¼ì˜í•´ì£¼ì„¸ìš”.

ë‹µë³€ í˜•ì‹ (JSON í˜•ì‹ì„ ì •í™•íˆ ì§€ì¼œì„œ ë‹µë³€í•´ì£¼ì„¸ìš”):
{
  "local_name": ["ê²½ê¸°ë„ íŒŒì£¼ì‹œ", "ê²½ê¸°ë„ ë‚¨ì–‘ì£¼ì‹œ", "ì „êµ­ ìì¹˜ë‹¨ì²´"],
  "range_date": ["1993~2004", "2004 ~ 2008", "2009 ~ 2025"]
}

ì¤‘ìš”:
- ê³¼ì„¸ì‚¬ì‹¤ì´ í•˜ë‚˜ë¼ë„ ìˆë‹¤ë©´ {"local_name": null, "range_date": null}ì„ ë°˜í™˜í•´ì£¼ì„¸ìš”.
- local_nameê³¼ range_dateëŠ” ë¬¸ìì—´ë§Œ ë°˜í™˜í•´ì£¼ì„¸ìš”.
- JSON í‚¤ëŠ” ë°˜ë“œì‹œ í°ë”°ì˜´í‘œë¡œ ê°ì‹¸ì£¼ì„¸ìš”.
"""

if __name__ == "__main__":
    # ë‹¤ìš´ë¡œë“œ í´ë” ê²½ë¡œ
    download_folder = pathlib.Path(r'C:\Users\HP\Desktop\GyeonggooLee\controller\download')
    
    # test_results.json ê¸°ì¤€ìœ¼ë¡œ RN/ì¹´í…Œê³ ë¦¬/íŒŒì¼ëª… êµ¬ì„± (ìš°ì„  ì‚¬ìš©), ì—†ìœ¼ë©´ í´ë” ìŠ¤ìº”
    rn_info_list = []
    json_path = 'test_results.json'
    try:
        # tesla001 ëª¨ë“œ: threads_filtered JSON ê¸°ì¤€ìœ¼ë¡œ RN/ì¹´í…Œê³ ë¦¬ êµ¬ì„± + í´ë” ê²½ë¡œ temp_downloadë¡œ êµì²´
        if len(sys.argv) > 1 and sys.argv[1] == 'tesla001':
            download_folder = pathlib.Path(r'C:\Users\HP\Desktop\GyeonggooLee\controller\temp_download')
            threads_json_path = os.path.join('í…ŒìŠ¬ë¼1íŒ€ì •ë³´', 'threads_filtered_20251030_140141.json')
            if os.path.exists(threads_json_path):
                with open(threads_json_path, 'r', encoding='utf-8') as f:
                    threads = json.load(f)
                    for item in threads:
                        rn = item.get('rn')
                        category = item.get('priority')  # priority.pyì—ì„œ ì±„ìš´ ê°’ ì‚¬ìš©
                        if rn and category:
                            # íŒŒì¼ëª…ì€ RNë§Œ ì‚¬ìš© (ì¹´í…Œê³ ë¦¬ ì ‘ë¯¸ì–´ ê¸ˆì§€)
                            filename = f"{rn}.pdf"
                            rn_info_list.append({'rn': rn, 'category': category, 'filename': filename})
                if rn_info_list:
                    print(f"âœ… threads_filtered JSON ê¸°ì¤€ {len(rn_info_list)}ê±´ ë¡œë“œ (tesla001)")
            else:
                print(f"âš ï¸  threads JSONì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {threads_json_path}")

        # ê¸°ë³¸ ê²½ë¡œ: test_results.json â†’ í´ë” ìŠ¤ìº”
        if not rn_info_list and os.path.exists(json_path):
            with open(json_path, 'r', encoding='utf-8') as f:
                items = json.load(f)
                # mail_download.pyì—ì„œ ì €ì¥í•œ all_rn_info í¬ë§· ê°€ì •: {RN, category, ...}
                for item in items:
                    rn = item.get('RN')
                    category = item.get('category')
                    if rn and category:
                        filename = f"{rn}_{category.replace('_', '_')}.pdf"
                        rn_info_list.append({'rn': rn, 'category': category, 'filename': filename})
            if rn_info_list:
                print(f"âœ… test_results.jsonì—ì„œ {len(rn_info_list)}ê±´ ë¡œë“œ")
        
        if not rn_info_list:
            # í´ë” ìŠ¤ìº” í´ë°±
            for f in os.listdir(download_folder):
                if f.endswith('.pdf'):
                    parts = f.replace('.pdf', '').split('_')
                    if len(parts) >= 2:
                        rn = parts[0]
                        category = "_".join(parts[1:])
                        rn_info_list.append({'rn': rn, 'category': category, 'filename': f})
                    else:
                        print(f"âš ï¸  íŒŒì¼ëª… í˜•ì‹ ì˜¤ë¥˜ (ë¬´ì‹œ): {f}")
    except Exception as e:
        print(f"âš ï¸  RN ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
    
    if not rn_info_list:
        print("âŒ ì²˜ë¦¬í•  RN ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤ (test_results.json/í´ë” ëª¨ë‘ ë¹„ì–´ìˆìŒ).")
        exit()

    # Supabase ë§¤ë‹ˆì € ì´ˆê¸°í™”
    supabase_manager = None
    try:
        # Supabase í”„ë¡œì íŠ¸ ì •ë³´
        supabase_url = "https://qehjythxhuaxkuotowjq.supabase.co"
        supabase_key = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InFlaGp5dGh4aHVheGt1b3Rvd2pxIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NjA0ODYwMTYsImV4cCI6MjA3NjA2MjAxNn0.VbzUwkXInOUS4Afj11F0wu_mn244glyIXsDHmE7NDho"
        
        supabase_manager = SupabaseManager(url=supabase_url, key=supabase_key)
        if supabase_manager.test_connection():
            print("âœ… Supabase ì—°ê²° ì„±ê³µ!")
        else:
            print("âŒ Supabase ì—°ê²° ì‹¤íŒ¨!")
            supabase_manager = None
    except Exception as e:
        print(f"âŒ Supabase ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        supabase_manager = None
    
    # Supabase ê¸°ì¤€ìœ¼ë¡œ ì´ë¯¸ ì²˜ë¦¬ëœ RN ì œì™¸ (ìš”ì²­/ê²°ê³¼ ëª¨ë‘ ê±´ë„ˆëœ€)
    try:
        if supabase_manager:
            existing_rows = supabase_manager.get_test_results()
            existing_rns = set(row.get('RN') for row in existing_rows if row and row.get('RN'))
            original_count = len(rn_info_list)
            rn_info_list = [info for info in rn_info_list if info['rn'] not in existing_rns]
            filtered_count = len(rn_info_list)
            excluded = original_count - filtered_count
            if excluded > 0:
                print(f"âš ï¸  Supabaseì— ê¸°ì¡´ ê¸°ë¡ì´ ìˆëŠ” RN {excluded}ê±´ ì œì™¸ ({filtered_count}ê±´ ì²˜ë¦¬ ì˜ˆì •)")
            if filtered_count == 0:
                print("ëª¨ë“  RNì´ Supabaseì— ì´ë¯¸ ì¡´ì¬í•˜ì—¬ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                exit()
    except Exception as e:
        print(f"âš ï¸  Supabase ê¸°ì¡´ RN í•„í„°ë§ ì¤‘ ì˜¤ë¥˜: {e}")
    
    # ì—¬ëŸ¬ RN ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘
    print(f"\nğŸ¯ {len(rn_info_list)}ê°œ RN ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘...")
    
    all_results, total_time, individual_times = process_multiple_rns(
        rn_info_list,
        download_folder,
        supabase_manager
    )

    # tesla001 ëª¨ë“œì—ì„œ ìœ íš¨ íŒŒì¼ì´ ì—†ì–´ ì²˜ë¦¬ ê²°ê³¼ê°€ ë¹„ì–´ìˆìœ¼ë©´ ì¡°ê¸° ì¢…ë£Œí•˜ì—¬ ìš”ì•½ ë‹¨ê³„ ì˜¤ë¥˜ ë°©ì§€
    if len(sys.argv) > 1 and sys.argv[1] == 'tesla001':
        if not all_results:
            print("\nâŒ tesla001: ì²˜ë¦¬í•  ìœ íš¨í•œ íŒŒì¼ì´ ì—†ì–´ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            exit()
    
    # ìµœì¢… ê²°ê³¼ ì¶œë ¥
    print("\n" + "="*60)
    print("ğŸ¯ ìµœì¢… ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½")
    print("="*60)
    
    success_count = 0
    for rn, result in all_results.items():
        # ê° ê²°ê³¼ì—ì„œ ì„±ê³µí•œ ì¹´í…Œê³ ë¦¬ í™•ì¸
        contract_success = result.get('contract_data') is not None
        resident_success = result.get('resident_cert_data') is not None
        dajanyeo_success = result.get('dajanyeo_data') is not None
        cheongnyeon_success = result.get('cheongnyeon_data') is not None

        individual_time = individual_times.get(rn, 0)
        
        # ì„±ê³µ ì—¬ë¶€ íŒë‹¨ (ëª¨ë“  í•„ìˆ˜ í•­ëª©ì´ ì„±ê³µí–ˆëŠ”ì§€)
        # íŒŒì¼ì˜ ì¹´í…Œê³ ë¦¬ì— ë”°ë¼ í•„ìˆ˜ í•­ëª©ì´ ë‹¬ë¼ì§
        category = next((item['category'] for item in rn_info_list if item['rn'] == rn), "")
        
        is_fully_successful = contract_success and resident_success
        if 'ë‹¤ìë…€' in category:
            is_fully_successful = is_fully_successful and dajanyeo_success
        if 'ì²­ë…„ìƒì• ' in category:
            is_fully_successful = is_fully_successful and cheongnyeon_success
        
        if is_fully_successful:
            success_count += 1
            print(f"âœ… {rn} ({category}): ëª¨ë“  í•­ëª© ì²˜ë¦¬ ì„±ê³µ ({individual_time:.1f}s)")
        else:
            status = []
            if contract_success: status.append("ê³„ì•½ì„œ")
            if resident_success: status.append("ì´ˆë³¸")
            if dajanyeo_success: status.append("ë‹¤ìë…€")
            if cheongnyeon_success: status.append("ì²­ë…„ìƒì• ")
            
            if not status:
                print(f"âŒ {rn} ({category}): ëª¨ë“  í•­ëª© ì²˜ë¦¬ ì‹¤íŒ¨ ({individual_time:.1f}s)")
            else:
                print(f"âš ï¸  {rn} ({category}): ë¶€ë¶„ ì„±ê³µ - {', '.join(status)} ({individual_time:.1f}s)")

    # ì‹œê°„ í†µê³„ ê³„ì‚°
    valid_times = [t for t in individual_times.values() if t > 0]
    avg_time = sum(valid_times) / len(valid_times) if valid_times else 0
    total_rn_count = len(rn_info_list)
    
    print(f"\nğŸ“Š ì „ì²´ ì„±ê³µë¥ : {success_count}/{total_rn_count} ({success_count/total_rn_count*100:.1f}%)")
    print(f"\nâ±ï¸  ì‹œê°„ í†µê³„:")
    print(f"   - ì´ ì²˜ë¦¬ ì‹œê°„: {total_time:.1f}ì´ˆ")
    print(f"   - RNë‹¹ í‰ê·  ì²˜ë¦¬ ì‹œê°„: {avg_time:.1f}ì´ˆ")
    if total_time > 0:
        print(f"   - ë³‘ë ¬ ì²˜ë¦¬ íš¨ìœ¨: {sum(valid_times)/total_time:.1f}x (ìˆœì°¨ ëŒ€ë¹„)")
    
    if supabase_manager:
        print(f"\nğŸ’¾ ëª¨ë“  ê²°ê³¼ê°€ Supabaseì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ëœ RN ëª©ë¡ì„ ì—‘ì…€ì—ì„œ ì œê±°
    successful_rns = [rn for rn, result in all_results.items() if result] # ê²°ê³¼ê°€ ìˆëŠ” ëª¨ë“  RNì„ ì„±ê³µìœ¼ë¡œ ê°„ì£¼
    excel_file_path = 'real.xlsx'
    remove_processed_rns_from_excel(excel_file_path, successful_rns)