from google import genai
from google.genai import types
import pathlib
import os
import re
import json
import time
import sys
from concurrent.futures import ThreadPoolExecutor, as_completed
import PyPDF2
import pymysql
from datetime import datetime

# ÏÉÅÏúÑ ÎîîÎ†âÌÜ†Î¶¨ Í≤ΩÎ°ú Ï∂îÍ∞Ä
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from config import API_KEY, SUB_API_KEY

client = genai.Client(api_key=API_KEY)
client_free = genai.Client(api_key=SUB_API_KEY)

# MySQL Ïó∞Í≤∞ ÏÑ§Ï†ï
DB_CONFIG = {
    'host': '192.168.0.114',
    'port': 3306,
    'user': 'my_pc_user',
    'password': '!Qdhdbrclf56',
    'db': 'greetlounge',
    'charset': 'utf8mb4'
}

def parse_response(text):
    """AI ÏùëÎãµÏóêÏÑú JSONÏùÑ ÌååÏã±ÌïòÏó¨ Ï£ºÎØºÎì±Î°ùÏ¥àÎ≥∏ Ï†ïÎ≥¥ Ï∂îÏ∂ú"""
    if text is None:
        return None
    
    try:
        # JSON Î∂ÄÎ∂ÑÎßå Ï∂îÏ∂ú (```json``` Î∏îÎ°ùÏù¥ ÏûàÏùÑ Ïàò ÏûàÏùå)
        json_match = re.search(r'\{.*\}', text, re.DOTALL)
        if json_match:
            json_str = json_match.group()
            data = json.loads(json_str)
            
            # ÏÑ±Î™Ö(name) ÌïÑÎìú ÌõÑÏ≤òÎ¶¨: Í≥µÎ∞±, Í∞úÌñâÎ¨∏Ïûê, ÌÉ≠ Ï†úÍ±∞
            if data.get('name'):
                data['name'] = data['name'].replace(' ', '').replace('\n', '').replace('\r', '').replace('\t', '')
            
            # Ï£ºÏÜå(address_1) ÌïÑÎìú ÌõÑÏ≤òÎ¶¨: ÎèÑ Ïù¥Î¶Ñ Î≥ÄÌôò
            if data.get('address_1'):
                address = data['address_1']
                # Í∞ïÏõêÎèÑ -> Í∞ïÏõêÌäπÎ≥ÑÏûêÏπòÎèÑ
                if 'Í∞ïÏõêÎèÑ' in address:
                    address = address.replace('Í∞ïÏõêÎèÑ', 'Í∞ïÏõêÌäπÎ≥ÑÏûêÏπòÎèÑ')
                # Ï†ÑÎùºÎ∂ÅÎèÑ -> Ï†ÑÎ∂ÅÌäπÎ≥ÑÏûêÏπòÎèÑ
                if 'Ï†ÑÎùºÎ∂ÅÎèÑ' in address:
                    address = address.replace('Ï†ÑÎùºÎ∂ÅÎèÑ', 'Ï†ÑÎ∂ÅÌäπÎ≥ÑÏûêÏπòÎèÑ')
                data['address_1'] = address
            
            # Ï£ºÏÜå(address_2) ÌïÑÎìú ÌõÑÏ≤òÎ¶¨: ÎèÑ Ïù¥Î¶Ñ Î≥ÄÌôò
            if data.get('address_2'):
                address = data['address_2']
                # Í∞ïÏõêÎèÑ -> Í∞ïÏõêÌäπÎ≥ÑÏûêÏπòÎèÑ
                if 'Í∞ïÏõêÎèÑ' in address:
                    address = address.replace('Í∞ïÏõêÎèÑ', 'Í∞ïÏõêÌäπÎ≥ÑÏûêÏπòÎèÑ')
                # Ï†ÑÎùºÎ∂ÅÎèÑ -> Ï†ÑÎ∂ÅÌäπÎ≥ÑÏûêÏπòÎèÑ
                if 'Ï†ÑÎùºÎ∂ÅÎèÑ' in address:
                    address = address.replace('Ï†ÑÎùºÎ∂ÅÎèÑ', 'Ï†ÑÎ∂ÅÌäπÎ≥ÑÏûêÏπòÎèÑ')
                data['address_2'] = address
            
            # Î∞úÍ∏âÏùº(issue_date) ÌïÑÎìú ÌõÑÏ≤òÎ¶¨: '2025ÎÖÑ 07Ïõî 03Ïùº' -> '2025-07-03'
            if data.get('issue_date'):
                issue_date = data['issue_date']
                # 'ÎÖÑ', 'Ïõî', 'Ïùº' Ìå®ÌÑ¥ÏúºÎ°ú ÌååÏã±
                date_match = re.search(r'(\d{4})ÎÖÑ\s*(\d{1,2})Ïõî\s*(\d{1,2})Ïùº', issue_date)
                if date_match:
                    year = date_match.group(1)
                    month = date_match.group(2).zfill(2)  # ÏõîÏùÑ 2ÏûêÎ¶¨Î°ú ÎßûÏ∂§
                    day = date_match.group(3).zfill(2)     # ÏùºÏùÑ 2ÏûêÎ¶¨Î°ú ÎßûÏ∂§
                    data['issue_date'] = f"{year}-{month}-{day}"
            
            return data
    except:
        pass
    
    return None

def is_valid_pdf(filepath):
    """PDF ÌååÏùºÏù¥ Ïú†Ìö®ÌïúÏßÄ Í≤ÄÏÇ¨ (ÌéòÏù¥ÏßÄÍ∞Ä ÏûàÎäîÏßÄ ÌôïÏù∏)"""
    try:
        with open(filepath, 'rb') as file:
            pdf_reader = PyPDF2.PdfReader(file)
            return len(pdf_reader.pages) > 0
    except Exception:
        return False

def save_to_mysql(rn, data):
    """Í≤∞Í≥ºÎ•º MySQL ÌÖåÏù¥Î∏îÏóê Ï†ÄÏû•"""
    try:
        connection = pymysql.connect(**DB_CONFIG)
        cursor = connection.cursor(pymysql.cursors.DictCursor)
        
        if data is None:
            data = {}
        
        # Îç∞Ïù¥ÌÑ∞ Îß§Ìïë
        address_1 = data.get('address_1')
        address_2 = data.get('address_2')
        at_date = data.get('at_date')
        birth_date = data.get('birth_date')
        name = data.get('name')
        issue_date = data.get('issue_date')
        page_number = json.dumps(data.get('page_number')) if data.get('page_number') else None
        modified_date = datetime.now()
        
        # INSERT ÎòêÎäî UPDATE (UPSERT)
        sql = """
        INSERT INTO test_ai_Ï¥àÎ≥∏ (RN, modified_date, address_1, address_2, at_date, birth_date, name, issue_date, page_number)
        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
        ON DUPLICATE KEY UPDATE
            modified_date = VALUES(modified_date),
            address_1 = VALUES(address_1),
            address_2 = VALUES(address_2),
            at_date = VALUES(at_date),
            birth_date = VALUES(birth_date),
            name = VALUES(name),
            issue_date = VALUES(issue_date),
            page_number = VALUES(page_number)
        """
        
        cursor.execute(sql, (rn, modified_date, address_1, address_2, at_date, birth_date, name, issue_date, page_number))
        connection.commit()
        cursor.close()
        connection.close()
        return True
    except Exception as e:
        print(f"‚ùå MySQL Ï†ÄÏû• Ïã§Ìå® ({rn}): {e}")
        return False

RN_LIST = ['RN126116642']

print(f"üöÄ Ï¥ù {len(RN_LIST)}Í∞úÏùò RN Ï≤òÎ¶¨ ÏãúÏûë")

folder_pat = r'\\DESKTOP-KMJ\Users\HP\Desktop\greet_db\files\new'

# RN_LISTÏóê Ìè¨Ìï®Îêú RNÎ≤àÌò∏Í∞Ä ÌååÏùºÎ™ÖÏóê Îì§Ïñ¥Í∞Ñ ÌååÏùºÎßå Í≥®Îùº RN_LIST Í∞úÏàòÏôÄ ÏùºÏπòÌïòÍ≤å FILES_PATH Î¶¨Ïä§Ìä∏Ïóê Ï†ÄÏû•
FILES_PATH = []
if os.path.isdir(folder_pat):
    files = os.listdir(folder_pat)
    for rn in RN_LIST:
        matched_file = next((f for f in files if rn in f), None)
        if matched_file:
            FILES_PATH.append(os.path.join(folder_pat, matched_file))
        else:
            FILES_PATH.append(None)  # RNÏù¥ Ìè¨Ìï®Îêú ÌååÏùºÏù¥ ÏóÜÏúºÎ©¥ NoneÏúºÎ°ú ÌëúÍ∏∞
else:
    FILES_PATH = [None] * len(RN_LIST)

prompt = """Ï£ºÎØºÎì±Î°ùÏ¥àÎ≥∏ÏóêÏÑú Îã§Ïùå Ï†ïÎ≥¥Î•º Ï∞æÏïÑÏÑú JSON ÌòïÏãùÏúºÎ°ú ÎãµÎ≥ÄÌï¥Ï£ºÏÑ∏Ïöî:

1. Î™®Îì† ÌéòÏù¥ÏßÄÏóêÏÑú 'ÎßàÏßÄÎßâ Î≤àÌò∏'Ïóê Ìï¥ÎãπÌïòÎäî ['Ï£ºÏÜå', 'Î∞úÏÉùÏùº'] Ï†ïÎ≥¥Î•º Ï∂îÏ∂úÌï¥Ï£ºÏÑ∏Ïöî. Î∞úÏÉùÏùºÏùÄ at_date ÌïÑÎìúÏóê Ï†ÄÏû•Ìï¥Ï£ºÏÑ∏Ïöî.
2. 'Ï£ºÏÜå'Îäî ÎåÄÎ∂ÄÎ∂Ñ 2Ï§ÑÎ°ú ÎêòÏñ¥ ÏûàÎäîÎç∞ 2Ï§ÑÏùÑ Í∞ÅÍ∞Å [address_1, address_2] ÌòïÏãùÏúºÎ°ú Ï∂îÏ∂úÌï¥Ï£ºÏÑ∏Ïöî. ',' ÏâºÌëúÏôÄ '.' Î¨∏ÏûêÎäî Ï†úÍ±∞Ìï¥Ï£ºÏÑ∏Ïöî.
3. 'Î∞úÏÉùÏùº'ÏùÄ YYYY-MM-DD ÌòïÏãùÏúºÎ°ú Ï∂îÏ∂úÌï¥Ï£ºÏÑ∏Ïöî.
4. 'ÏÑ±Î™Ö', 'Ï£ºÎØºÎì±Î°ùÎ≤àÌò∏'Î•º Ï∂îÏ∂úÌïú ÌõÑ Ïïû 6ÏûêÎ¶¨Ïùò Ïà´ÏûêÎ•º birth_date ÌïÑÎìúÏóê Ï†ÄÏû•Ìï¥Ï£ºÏÑ∏Ïöî. 950516-1234567 -> 1995-05-16
5. ÏïÑÎ¨¥ ÌéòÏù¥ÏßÄ ÏÉÅÎã®Ïóê '2025ÎÖÑ' Ïù¥ÎùºÎäî Î¨∏ÏûêÏó¥ÏùÑ Ï∞æÏïÑÏÑú ÏùºÏûê Ï†ÑÏ≤¥Î•º Ï∞æÏïÑÏ£ºÏÑ∏Ïöî. issue_date ÌïÑÎìúÏóê Ï†ÄÏû•Ìï¥Ï£ºÏÑ∏Ïöî.
6. Ï£ºÎØºÎì±Î°ùÏ¥àÎ≥∏ Îç∞Ïù¥ÌÑ∞Í∞Ä Ìè¨Ìï®Îêú Î™®Îì† ÌéòÏù¥ÏßÄ Î≤àÌò∏Î•º page_number ÌïÑÎìúÏóê Î¶¨Ïä§Ìä∏ ÌòïÌÉúÎ°ú Ï†ÄÏû•Ìï¥Ï£ºÏÑ∏Ïöî.
7. Ï¥àÎ≥∏Ïù¥ ÏóÜÎã§Í≥† ÌåêÎã®ÎêòÎ©¥ Î™®Îì† Í∞íÏùÑ NoneÏúºÎ°ú Î∞òÌôòÌï¥Ï£ºÏÑ∏Ïöî.


ÎãµÎ≥Ä ÌòïÏãù:
{
  address_1: "ÏÑúÏö∏ÌäπÎ≥ÑÏãú Í∞ïÎÇ®Íµ¨ Ïó≠ÏÇºÎèô 123-45",
  address_2: "ÏûêÏù¥ÏïÑÌååÌä∏ 101Îèô 101Ìò∏"
  at_date: "2025-04-16",
  birth_date: "1999-10-06",
  name: "ÌôçÍ∏∏Îèô",
  issue_date: "2025-04-16",
  page_number: [3, 4, 5]
}

Ï£ºÏÜåÏôÄ Î∞úÏÉùÏùºÏùÄ Î™®Îì† ÌéòÏù¥ÏßÄ Ï§ëÏóêÏÑú 'Î≤àÌò∏'Í∞Ä Í∞ÄÏû• ÎÜíÏùÄ rowÏóê ÎåÄÌï¥ÏÑú Ï∂îÏ∂úÌï¥Ï£ºÏÑ∏Ïöî. ÎßàÏßÄÎßâ ÌéòÏù¥ÏßÄÍ∞Ä ÏïÑÎãå Í∞ÄÏû• ÌÅ∞ Î≤àÌò∏Í∞Ä Ìè¨Ìï®Îêú ÌéòÏù¥ÏßÄÏóêÏÑú Ï∂îÏ∂úÌï¥Ï£ºÏÑ∏Ïöî.
Ï¥àÎ≥∏Ïù¥ 1ÌéòÏù¥ÏßÄÎßå ÏûàÏúºÎ©¥ [3], Ïó¨Îü¨ ÌéòÏù¥ÏßÄÏóê Í±∏Ï≥êÏûàÏúºÎ©¥ [3, 4, 5, 6]Ï≤òÎüº Î™®Îì† ÌéòÏù¥ÏßÄ Î≤àÌò∏Î•º Ìè¨Ìï®Ìï¥Ï£ºÏÑ∏Ïöî.

issue_date Ï∂îÏ∂ú Ïãú Ï£ºÏùòÏÇ¨Ìï≠:
- Ìï≠ÏÉÅ '0000ÎÖÑ 0Ïõî 00Ïùº' Ï≤òÎüº Ïì∞Ïó¨Ï†∏ ÏûàÏäµÎãàÎã§.
- '0000-00-00' ÏúºÎ°ú Ïì∞Ïó¨Ï†∏ ÏûàÏßÄ ÏïäÏäµÎãàÎã§.
- Ìï≠ÏÉÅ '2025ÎÖÑ' Ïù¥ÎùºÎäî Î¨∏ÏûêÏó¥ÏùÑ Ï∞æÏïÑÏÑú ÏùºÏûê Ï†ÑÏ≤¥Î•º Ï∞æÏïÑÏ£ºÏÑ∏Ïöî.
- ÎåÄÎ∂ÄÎ∂Ñ ÌéòÏù¥ÏßÄ ÏÉÅÎã®Ïóê Ï°¥Ïû¨Ìï©ÎãàÎã§.
"""

results = {}
skipped_rns = []  # ÌååÏùºÏù¥ ÏóÜÎäî RN Ï∂îÏ†Å

def _process_single_pdf_with_free_api(rn, filepath, prompt_text):
    """Î¨¥Î£å APIÎ°ú Îã®Ïùº PDF Ï≤òÎ¶¨ (Ïú†Î£å API Ïã§Ìå® Ïãú ÏÇ¨Ïö©)"""
    start_time = time.time()
    max_retries = 3
    for attempt_index in range(max_retries):
        try:
            if attempt_index > 0:
                print(f"  ‚è≥ Î¨¥Î£å API Ïû¨ÏãúÎèÑ {attempt_index}ÌöåÏ∞®... 10Ï¥à ÎåÄÍ∏∞ Ï§ë")
                time.sleep(10)
            else:
                time.sleep(6)
                
            response = client_free.models.generate_content(
                model="gemini-2.5-flash",
                contents=[
                    types.Part.from_bytes(
                        data=pathlib.Path(filepath).read_bytes(),
                        mime_type='application/pdf',
                    ),
                    prompt_text
                ]
            )
            extracted_data = parse_response(response.text)
            elapsed_time = time.time() - start_time
            print(f"  ‚úÖ Î¨¥Î£å APIÎ°ú Ï≤òÎ¶¨ ÏÑ±Í≥µ!")
            if extracted_data:
                extracted_data['process_seconds'] = round(elapsed_time, 2)
            return rn, extracted_data
        except Exception as e:
            if attempt_index < max_retries - 1:
                print(f"  ‚ö†Ô∏è  Î¨¥Î£å API Ïò§Î•ò: {e}")
                time.sleep(15 * (2 ** attempt_index))
            else:
                elapsed_time = time.time() - start_time
                print(f"  ‚ùå Î¨¥Î£å APIÎ°úÎèÑ Ï≤òÎ¶¨ Ïã§Ìå®: {e}")
                return rn, {'process_seconds': round(elapsed_time, 2)} if extracted_data is None else None

def _process_single_pdf(rn, filepath, prompt_text, max_retries=5, initial_backoff_sec=2.0):
    """Îã®Ïùº PDF Ï≤òÎ¶¨ (Í∞úÏÑ†Îêú Î≤ÑÏ†Ñ)"""
    start_time = time.time()
    backoff = initial_backoff_sec
    for attempt_index in range(max_retries):
        try:
            if attempt_index > 0:
                time.sleep(5)
                
            response = client.models.generate_content(
                model="gemini-2.5-flash",
                contents=[
                    types.Part.from_bytes(
                        data=pathlib.Path(filepath).read_bytes(),
                        mime_type='application/pdf',
                    ),
                    prompt_text
                ]
            )
            extracted_data = parse_response(response.text)
            elapsed_time = time.time() - start_time
            if extracted_data:
                extracted_data['process_seconds'] = round(elapsed_time, 2)
            return rn, extracted_data
        except Exception as e:
            if attempt_index < max_retries - 1:
                sleep_sec = backoff * (1.0 + 0.25 * (os.urandom(1)[0] / 255.0))
                time.sleep(sleep_sec)
                backoff *= 2.0
            else:
                elapsed_time = time.time() - start_time
                print(f"ÌååÏùº Ï≤òÎ¶¨ Ï§ë Ïò§Î•ò Î∞úÏÉù(ÏµúÏ¢Ö Ïã§Ìå®): {filepath}, Ïò§Î•ò: {e}")
                return rn, {'process_seconds': round(elapsed_time, 2)}

# Ïú†Î£å APIÎ•º ÏÇ¨Ïö©ÌïòÏó¨ 3Í∞úÏî© ÏàúÏ∞® Î∞∞Ïπò, Î∞∞Ïπò ÎÇ¥ ÎèôÏãú 2Í∞ú Ï≤òÎ¶¨
print("üöÄ Gemini APIÎ•º ÏÇ¨Ïö©ÌïòÏó¨ Ï≤òÎ¶¨ Ï§ë...")

# PDF ÌååÏùºÏù¥ ÏóÜÎäî RNÎì§ÏùÄ Í±¥ÎÑàÎõ∞Í∏∞
for i, filepath in enumerate(FILES_PATH):
    rn = RN_LIST[i]
    if filepath is None:
        print(f"‚ö†Ô∏è  {rn}: PDF ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏùå - Ï≤òÎ¶¨ Í±¥ÎÑàÎúÄ")
        skipped_rns.append(rn)

# PDF ÌååÏùºÏù¥ ÏûàÎäî RNÎì§ÏùÑ 3Í∞úÏî© Î¨∂Ïñ¥ÏÑú Ï≤òÎ¶¨ (Ïú†Ìö®Ìïú PDFÎßå)
valid_files = []
for i in range(len(RN_LIST)):
    if FILES_PATH[i] is not None:
        if is_valid_pdf(FILES_PATH[i]):
            valid_files.append((RN_LIST[i], FILES_PATH[i]))
        else:
            print(f"‚ö†Ô∏è  {RN_LIST[i]}: PDF ÌååÏùºÏù¥ ÏÜêÏÉÅÎêòÏóàÍ±∞ÎÇò Îπà ÌååÏùºÏûÖÎãàÎã§.")
            results[RN_LIST[i]] = {'process_seconds': 0}

batch_size = 3
for i in range(0, len(valid_files), batch_size):
    batch_files = valid_files[i:i + batch_size]
    print(f"üì¶ Batch {i//batch_size + 1}: {len(batch_files)}Í∞ú ÌååÏùº Ï≤òÎ¶¨ Ï§ë...")
    
    with ThreadPoolExecutor(max_workers=2) as executor:
        futures = []
        for rn, filepath in batch_files:
            future = executor.submit(_process_single_pdf, rn, filepath, prompt)
            futures.append(future)
            time.sleep(0.5)
        
        for future in as_completed(futures):
            rn_key, rn_result = future.result()
            results[rn_key] = rn_result
    
    print(f"‚úÖ Batch {i//batch_size + 1} ÏôÑÎ£å")
    
    if i + batch_size < len(valid_files):
        time.sleep(10)

# Ïú†Î£å APIÎ°ú Ïã§Ìå®Ìïú ÌååÏùºÎì§ÏùÑ Î¨¥Î£å APIÎ°ú Ïû¨Ï≤òÎ¶¨
failed_files = [(rn, filepath) for rn, filepath in valid_files 
                if results.get(rn) is None and is_valid_pdf(filepath)]

if failed_files:
    print("\n" + "="*60)
    print(f"‚ö†Ô∏è  Ïú†Î£å APIÎ°ú Ïã§Ìå®Ìïú {len(failed_files)}Í∞ú ÌååÏùºÏùÑ Î¨¥Î£å APIÎ°ú Ïû¨Ï≤òÎ¶¨Ìï©ÎãàÎã§.")
    print("="*60)
    
    for idx, (rn, filepath) in enumerate(failed_files, 1):
        print(f"\nüîÑ [{idx}/{len(failed_files)}] {rn} Î¨¥Î£å APIÎ°ú Ïû¨Ï≤òÎ¶¨ Ï§ë...")
        rn_key, rn_result = _process_single_pdf_with_free_api(rn, filepath, prompt)
        results[rn_key] = rn_result

print("\n" + "="*60)
print("Ï£ºÎØºÎì±Î°ùÏ¥àÎ≥∏ OCR Ï∂îÏ∂ú ÏôÑÎ£å!")
print("="*60)

# Í≤∞Í≥ºÎ•º MySQLÏóê Ï†ÄÏû•
print("\nüíæ MySQLÏóê Ï†ÄÏû• Ï§ë...")
saved_count = 0
failed_count = 0

for rn, data in results.items():
    if save_to_mysql(rn, data):
        saved_count += 1
    else:
        failed_count += 1

print(f"\n‚úÖ Ï†ÄÏû• ÏôÑÎ£å: {saved_count}Í∞ú ÏÑ±Í≥µ, {failed_count}Í∞ú Ïã§Ìå®")
print("\n" + "="*60)

